{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Falcon3-7B-Instruct with QLoRA and SageMaker remote decorator\n",
    "\n",
    "## Question & Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this demo notebook, we demonstrate how to fine-tune the Falcon3-7B-Instruct model using QLoRA, Hugging Face PEFT, and bitsandbytes.\n",
    "\n",
    "We are using SageMaker remote decorator for runinng the fine-tuning job on Amazon SageMaker Training job\n",
    "---\n",
    "\n",
    "JupyterLab Instance Type: ml.t3.medium\n",
    "\n",
    "PyTorch version: 3.11\n",
    "\n",
    "Fine-Tuning:\n",
    "* Instance Type: ml.g5.12xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libriaries, including the Hugging Face libraries, and restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T12:38:06.851473Z",
     "start_time": "2023-07-20T12:38:04.440644Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup Configuration file path\n",
    "\n",
    "We are setting the directory in which the config.yaml file resides so that remote decorator can make use of the settings through [SageMaker Defaults](https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk).\n",
    "\n",
    "This notebook is using the Hugging Face container for the `us-east-1` region. Make sure you are using the right image for your AWS region, otherwise edit [config.yaml](./config.yaml). Container Images are available [here](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T09:24:51.291677Z",
     "start_time": "2023-11-15T09:24:51.282905Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:46.949259Z",
     "iopub.status.busy": "2024-12-18T09:32:46.948054Z",
     "iopub.status.idle": "2024-12-18T09:32:46.953756Z",
     "shell.execute_reply": "2024-12-18T09:32:46.952885Z",
     "shell.execute_reply.started": "2024-12-18T09:32:46.948956Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set path to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and upload the dataset\n",
    "\n",
    "We are going to load [rajpurkar/squad](https://huggingface.co/datasets/rajpurkar/squad) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T09:24:55.572481Z",
     "start_time": "2023-11-15T09:24:52.575954Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:47.473950Z",
     "iopub.status.busy": "2024-12-18T09:32:47.473580Z",
     "iopub.status.idle": "2024-12-18T09:32:55.294205Z",
     "shell.execute_reply": "2024-12-18T09:32:55.292227Z",
     "shell.execute_reply.started": "2024-12-18T09:32:47.473923Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                    answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"rajpurkar/squad\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df = df.iloc[0:1000]\n",
    "df['answer'] = [answer['text'][0] for answer in df['answers']]\n",
    "df = df[['context', 'question', 'answer']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:00.270970Z",
     "start_time": "2023-09-03T00:01:59.205060Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:55.295494Z",
     "iopub.status.busy": "2024-12-18T09:32:55.294979Z",
     "iopub.status.idle": "2024-12-18T09:32:55.756243Z",
     "shell.execute_reply": "2024-12-18T09:32:55.755527Z",
     "shell.execute_reply.started": "2024-12-18T09:32:55.295451Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train elements:  900\n",
      "Number of test elements:  100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Number of train elements: \", len(train))\n",
    "print(\"Number of test elements: \", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a prompt template and load the dataset with a random sample to try summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:01.435195Z",
     "start_time": "2023-09-03T00:02:01.429794Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:55.760387Z",
     "iopub.status.busy": "2024-12-18T09:32:55.759978Z",
     "iopub.status.idle": "2024-12-18T09:32:55.764400Z",
     "shell.execute_reply": "2024-12-18T09:32:55.763765Z",
     "shell.execute_reply.started": "2024-12-18T09:32:55.760366Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# custom instruct prompt start\n",
    "prompt_template = f\"\"\"<|user|>\\nContext:\\n{{context}}\\n\\n{{question}}<|assistant|>\\n{{answer}}<|endoftext|>\"\"\"\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = prompt_template.format(context=sample[\"context\"],\n",
    "                                            question=sample[\"question\"],\n",
    "                                            answer=sample[\"answer\"])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Hugging Face Trainer class to fine-tune the model. Define the hyperparameters we want to use. We also create a DataCollator that will take care of padding our inputs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:10.364459Z",
     "start_time": "2023-09-03T00:02:09.672705Z"
    },
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:55.767208Z",
     "iopub.status.busy": "2024-12-18T09:32:55.766995Z",
     "iopub.status.idle": "2024-12-18T09:32:55.887951Z",
     "shell.execute_reply": "2024-12-18T09:32:55.886970Z",
     "shell.execute_reply.started": "2024-12-18T09:32:55.767188Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e447b9b3bbe483fbd02dd2a5c81e7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Context:\n",
      "The group changed their name to Destiny's Child in 1996, based upon a passage in the Book of Isaiah. In 1997, Destiny's Child released their major label debut song \"Killing Time\" on the soundtrack to the 1997 film, Men in Black. The following year, the group released their self-titled debut album, scoring their first major hit \"No, No, No\". The album established the group as a viable act in the music industry, with moderate sales and winning the group three Soul Train Lady of Soul Awards for Best R&B/Soul Album of the Year, Best R&B/Soul or Rap New Artist, and Best R&B/Soul Single for \"No, No, No\". The group released their multi-platinum second album The Writing's on the Wall in 1999. The record features some of the group's most widely known songs such as \"Bills, Bills, Bills\", the group's first number-one single, \"Jumpin' Jumpin'\" and \"Say My Name\", which became their most successful song at the time, and would remain one of their signature songs. \"Say My Name\" won the Best R&B Performance by a Duo or Group with Vocals and the Best R&B Song at the 43rd Annual Grammy Awards. The Writing's on the Wall sold more than eight million copies worldwide. During this time, Beyoncé recorded a duet with Marc Nelson, an original member of Boyz II Men, on the song \"After All Is Said and Done\" for the soundtrack to the 1999 film, The Best Man.\n",
      "\n",
      "For which song, did Destiny's Child take home the grammy award for best R&B performance?<|assistant|>\n",
      "\"Say My Name\"<|endoftext|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777aef8ee16245c0b4231a9195e94e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(template_dataset, remove_columns=list(dataset[\"train\"].features))\n",
    "\n",
    "print(train_dataset[randint(0, len(dataset))][\"text\"])\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(template_dataset, remove_columns=list(dataset[\"test\"].features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To train our model, we need to convert our inputs (text) to token IDs. This is done by a Hugging Face Transformers Tokenizer. In addition to QLoRA, we will use bitsanbytes 4-bit precision to quantize out frozen LLM to 4-bit and attach LoRA adapters on it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:00.274387Z",
     "start_time": "2023-09-03T00:02:00.272283Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:55.891849Z",
     "iopub.status.busy": "2024-12-18T09:32:55.891633Z",
     "iopub.status.idle": "2024-12-18T09:32:55.896518Z",
     "shell.execute_reply": "2024-12-18T09:32:55.895945Z",
     "shell.execute_reply.started": "2024-12-18T09:32:55.891830Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility method for finding the target modules and update the necessary matrices. Visit [this](https://github.com/artidoro/qlora/blob/main/qlora.py) link for additional info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:19.168388Z",
     "start_time": "2023-09-03T00:02:18.153692Z"
    },
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:55.899377Z",
     "iopub.status.busy": "2024-12-18T09:32:55.899178Z",
     "iopub.status.idle": "2024-12-18T09:32:57.722575Z",
     "shell.execute_reply": "2024-12-18T09:32:57.721886Z",
     "shell.execute_reply.started": "2024-12-18T09:32:55.899357Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(hf_model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in hf_model.named_modules():\n",
    "        if isinstance(module, bnb.nn.Linear4bit):\n",
    "            names = name.split(\".\")\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove(\"lm_head\")\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:57.725488Z",
     "iopub.status.busy": "2024-12-18T09:32:57.725284Z",
     "iopub.status.idle": "2024-12-18T09:32:57.729660Z",
     "shell.execute_reply": "2024-12-18T09:32:57.728235Z",
     "shell.execute_reply.started": "2024-12-18T09:32:57.725467Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"tiiuae/Falcon3-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T00:02:21.382486Z",
     "start_time": "2023-09-03T00:02:20.962208Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-18T09:32:57.755601Z",
     "iopub.status.busy": "2024-12-18T09:32:57.755381Z",
     "iopub.status.idle": "2024-12-18T09:33:08.776905Z",
     "shell.execute_reply": "2024-12-18T09:33:08.776158Z",
     "shell.execute_reply.started": "2024-12-18T09:32:57.755581Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 09:32:59.369838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Fetched defaults config from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Fetched defaults config from location: /home/sagemaker-user/public/amazon-sagemaker-llm-fine-tuning-remote-decorator\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.ImageUri\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.PreExecutionCommands\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.InstanceType\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.VpcConfig.Subnets\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.VpcConfig.SecurityGroupIds\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from huggingface_hub import login, snapshot_download\n",
    "import os\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sagemaker.remote_function import remote\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, set_seed\n",
    "import transformers\n",
    "\n",
    "# Start training\n",
    "@remote(\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    volume_size=100,\n",
    "    job_name_prefix=f\"train-{model_id.split('/')[-1].replace('.', '-')}\", \n",
    "    use_torchrun=True, # for distribution\n",
    "    nproc_per_node=4 #GPU number\n",
    ")\n",
    "def train_fn(\n",
    "        model_name,\n",
    "        train_ds,\n",
    "        test_ds=None,\n",
    "        lora_r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=2e-4,\n",
    "        num_train_epochs=1,\n",
    "        fsdp=\"\",\n",
    "        fsdp_config=None,\n",
    "        gradient_checkpointing=False,\n",
    "        merge_weights=False,\n",
    "        seed=42,\n",
    "        token=None\n",
    "):\n",
    "    def init_distributed():\n",
    "        # Initialize the process group\n",
    "        torch.distributed.init_process_group(backend=\"nccl\")  # Use \"gloo\" backend for CPU\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        torch.cuda.set_device(local_rank)\n",
    "\n",
    "        return local_rank\n",
    "\n",
    "    # Call this function at the beginning of your script\n",
    "    local_rank = init_distributed()\n",
    "\n",
    "    # Now you can use distributed functionalities\n",
    "    torch.distributed.barrier(device_ids=[local_rank])\n",
    "\n",
    "    os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    if token is not None:\n",
    "        login(token=token)\n",
    "\n",
    "    # Speed up model download\n",
    "    with accelerator.main_process_first():\n",
    "        if accelerator.is_main_process:\n",
    "            os.makedirs(\"/opt/ml/tmp_folder\", exist_ok=True)\n",
    "\n",
    "            snapshot_download(repo_id=model_name, local_dir=\"/opt/ml/tmp_folder\")\n",
    "\n",
    "    model_name = \"/opt/ml/tmp_folder\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Set Tokenizer pad Token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        # tokenize and chunk dataset\n",
    "        lm_train_dataset = train_ds.map(\n",
    "            lambda sample: tokenizer(sample[\"text\"]), remove_columns=list(train_ds.features)\n",
    "        )\n",
    "\n",
    "        print(f\"Total number of train samples: {len(lm_train_dataset)}\")\n",
    "\n",
    "        if test_ds is not None:\n",
    "            lm_test_dataset = test_ds.map(\n",
    "                lambda sample: tokenizer(sample[\"text\"]), remove_columns=list(test_ds.features)\n",
    "            )\n",
    "\n",
    "            print(f\"Total number of test samples: {len(lm_test_dataset)}\")\n",
    "        else:\n",
    "            lm_test_dataset = None\n",
    "\n",
    "    torch_dtype = torch.bfloat16\n",
    "\n",
    "    # Defining additional configs for FSDP\n",
    "    if fsdp != \"\" and fsdp_config is not None:\n",
    "        bnb_config_params = {\n",
    "            \"bnb_4bit_quant_storage\": torch_dtype\n",
    "        }\n",
    "\n",
    "        model_configs = {\n",
    "            \"torch_dtype\": torch_dtype\n",
    "        }\n",
    "\n",
    "        fsdp_configurations = {\n",
    "            \"fsdp\": fsdp,\n",
    "            \"fsdp_config\": fsdp_config,\n",
    "            \"gradient_checkpointing_kwargs\": {\n",
    "                \"use_reentrant\": False\n",
    "            },\n",
    "            \"tf32\": True\n",
    "        }\n",
    "    else:\n",
    "        bnb_config_params = dict()\n",
    "        model_configs = dict()\n",
    "        fsdp_configurations = dict()\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch_dtype,\n",
    "        **bnb_config_params\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        use_cache=not gradient_checkpointing,\n",
    "        cache_dir=\"/tmp/.cache\",\n",
    "        **model_configs\n",
    "    )\n",
    "\n",
    "    if fsdp == \"\" and fsdp_config is None:\n",
    "        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=gradient_checkpointing)\n",
    "\n",
    "    if gradient_checkpointing:\n",
    "        model.gradient_checkpointing_enable()\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=\"all-linear\",\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "    print_trainable_parameters(model)\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=lm_train_dataset,\n",
    "        eval_dataset=lm_test_dataset if lm_test_dataset is not None else None,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            gradient_checkpointing=gradient_checkpointing,\n",
    "            logging_strategy=\"steps\",\n",
    "            logging_steps=1,\n",
    "            log_on_each_node=False,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            bf16=True,\n",
    "            ddp_find_unused_parameters=False,\n",
    "            save_strategy=\"no\",\n",
    "            output_dir=\"outputs\",\n",
    "            **fsdp_configurations\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    if trainer.is_fsdp_enabled:\n",
    "        trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n",
    "\n",
    "    if merge_weights:\n",
    "        output_dir = \"/tmp/model\"\n",
    "\n",
    "        # merge adapter weights with base model and save\n",
    "        # save int 4 model\n",
    "        trainer.model.save_pretrained(output_dir, safe_serialization=False)\n",
    "\n",
    "        if accelerator.is_main_process:\n",
    "            # clear memory\n",
    "            del model\n",
    "            del trainer\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # load PEFT model\n",
    "            model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "                output_dir,\n",
    "                torch_dtype=torch.float16,\n",
    "                low_cpu_mem_usage=True,\n",
    "                trust_remote_code=True,\n",
    "            )\n",
    "    \n",
    "            # Merge LoRA and base model and save\n",
    "            model = model.merge_and_unload()\n",
    "            model.save_pretrained(\n",
    "                \"/opt/ml/model\", safe_serialization=True, max_shard_size=\"2GB\"\n",
    "            )\n",
    "    else:\n",
    "        trainer.model.save_pretrained(\"/opt/ml/model\", safe_serialization=True)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(\"/opt/ml/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-18T09:33:11.157642Z",
     "iopub.status.busy": "2024-12-18T09:33:11.157282Z",
     "iopub.status.idle": "2024-12-18T09:59:20.341345Z",
     "shell.execute_reply": "2024-12-18T09:59:20.340121Z",
     "shell.execute_reply.started": "2024-12-18T09:33:11.157618Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 09:33:11,159 sagemaker.remote_function INFO     Serializing function code to s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/function\n",
      "2024-12-18 09:33:11,258 sagemaker.remote_function INFO     Serializing function arguments to s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/arguments\n",
      "2024-12-18 09:33:11,650 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmpbenn2qe_/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2024-12-18 09:33:11,653 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpbenn2qe_/temp_workspace/sagemaker_remote_function_workspace/requirements.txt'\n",
      "2024-12-18 09:33:11,654 sagemaker.remote_function INFO     Generated pre-execution script from commands to '/tmp/tmpbenn2qe_/temp_workspace/sagemaker_remote_function_workspace/pre_exec.sh'\n",
      "2024-12-18 09:33:11,789 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmpbenn2qe_/workspace.zip'\n",
      "2024-12-18 09:33:11,920 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/sm_rf_user_ws/workspace.zip'\n",
      "2024-12-18 09:33:11,931 sagemaker.remote_function INFO     Creating job: train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-18 09:33:14 Starting - Starting the training job\n",
      "2024-12-18 09:33:14 Pending - Training job waiting for capacity......\n",
      "2024-12-18 09:34:16 Pending - Preparing the instances for training......\n",
      "2024-12-18 09:35:07 Downloading - Downloading the training image...........................\n",
      "2024-12-18 09:39:44 Training - Training image download completed. Training in progress......\u001b[34mINFO: CONDA_PKGS_DIRS is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/conda/pkgs'\u001b[0m\n",
      "\u001b[34mINFO: PIP_CACHE_DIR is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/pip'\u001b[0m\n",
      "\u001b[34mINFO: Bootstraping runtime environment.\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,024 sagemaker.remote_function INFO     Successfully unpacked workspace archive at '/'.\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,024 sagemaker.remote_function INFO     Running pre-execution commands in '/sagemaker_remote_function_workspace/pre_exec.sh'\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,026 sagemaker.remote_function INFO     Running command: '/opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U' in the dir: '/' \u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,468 sagemaker.remote_function INFO     Collecting transformers==4.47.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,498 sagemaker.remote_function INFO       Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,616 sagemaker.remote_function INFO     Collecting peft==0.13.2 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,621 sagemaker.remote_function INFO       Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,651 sagemaker.remote_function INFO     Collecting accelerate==1.1.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,654 sagemaker.remote_function INFO       Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,682 sagemaker.remote_function INFO     Collecting bitsandbytes==0.44.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,686 sagemaker.remote_function INFO       Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,717 sagemaker.remote_function INFO     Collecting datasets==3.1.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,721 sagemaker.remote_function INFO       Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,755 sagemaker.remote_function INFO     Collecting evaluate==0.4.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,760 sagemaker.remote_function INFO       Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,804 sagemaker.remote_function INFO     Collecting hf-transfer==0.1.8 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,808 sagemaker.remote_function INFO       Downloading hf_transfer-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:25,811 sagemaker.remote_function INFO     Requirement already satisfied: safetensors>=0.4.5 in /opt/conda/lib/python3.11/site-packages (from -r /sagemaker_remote_function_workspace/requirements.txt (line 8)) (0.4.5)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,018 sagemaker.remote_function INFO     Collecting sagemaker==2.235.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,023 sagemaker.remote_function INFO       Downloading sagemaker-2.235.1-py3-none-any.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,090 sagemaker.remote_function INFO     Collecting sentencepiece==0.2.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,095 sagemaker.remote_function INFO       Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,098 sagemaker.remote_function INFO     Requirement already satisfied: scikit-learn==1.5.2 in /opt/conda/lib/python3.11/site-packages (from -r /sagemaker_remote_function_workspace/requirements.txt (line 11)) (1.5.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,409 sagemaker.remote_function INFO     Collecting tokenizers>=0.21.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,414 sagemaker.remote_function INFO       Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,456 sagemaker.remote_function INFO     Collecting py7zr (from -r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,460 sagemaker.remote_function INFO       Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,471 sagemaker.remote_function INFO     Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.16.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,472 sagemaker.remote_function INFO     Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (0.26.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,472 sagemaker.remote_function INFO     Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,472 sagemaker.remote_function INFO     Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (24.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,473 sagemaker.remote_function INFO     Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (6.0.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,863 sagemaker.remote_function INFO     Collecting regex!=2019.12.17 (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,867 sagemaker.remote_function INFO       Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,872 sagemaker.remote_function INFO     Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2.32.3)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,877 sagemaker.remote_function INFO     Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (4.66.5)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,879 sagemaker.remote_function INFO     Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.13.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (6.1.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,879 sagemaker.remote_function INFO     Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.13.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (2.5.1+cu124)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,892 sagemaker.remote_function INFO     Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (18.0.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,905 sagemaker.remote_function INFO     Collecting dill<0.3.9,>=0.3.0 (from datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,909 sagemaker.remote_function INFO       Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:26,913 sagemaker.remote_function INFO     Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (2.2.3)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,039 sagemaker.remote_function INFO     Collecting xxhash (from datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,043 sagemaker.remote_function INFO       Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,067 sagemaker.remote_function INFO     Collecting multiprocess<0.70.17 (from datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,071 sagemaker.remote_function INFO       Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,101 sagemaker.remote_function INFO     Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,105 sagemaker.remote_function INFO       Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,582 sagemaker.remote_function INFO     Collecting aiohttp (from datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,586 sagemaker.remote_function INFO       Downloading aiohttp-3.11.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,684 sagemaker.remote_function INFO     Collecting responses<0.19 (from evaluate==0.4.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,688 sagemaker.remote_function INFO       Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,696 sagemaker.remote_function INFO     Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (23.2.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,697 sagemaker.remote_function INFO     Requirement already satisfied: boto3<2.0,>=1.34.142 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (1.35.63)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,697 sagemaker.remote_function INFO     Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (2.2.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,697 sagemaker.remote_function INFO     Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (7.1.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,697 sagemaker.remote_function INFO     Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.2.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,698 sagemaker.remote_function INFO     Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (6.11.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,698 sagemaker.remote_function INFO     Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (4.23.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,699 sagemaker.remote_function INFO     Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.3.3)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,699 sagemaker.remote_function INFO     Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (4.3.6)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,699 sagemaker.remote_function INFO     Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (3.20.3)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,712 sagemaker.remote_function INFO     Collecting sagemaker-core<2.0.0,>=1.0.15 (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,716 sagemaker.remote_function INFO       Downloading sagemaker_core-1.0.17-py3-none-any.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,720 sagemaker.remote_function INFO     Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.7.7)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,720 sagemaker.remote_function INFO     Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (1.0.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,720 sagemaker.remote_function INFO     Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (3.0.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,721 sagemaker.remote_function INFO     Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (1.26.19)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,729 sagemaker.remote_function INFO     Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 11)) (1.14.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,729 sagemaker.remote_function INFO     Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 11)) (1.4.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,729 sagemaker.remote_function INFO     Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 11)) (3.5.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,747 sagemaker.remote_function INFO     Collecting texttable (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,751 sagemaker.remote_function INFO       Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,856 sagemaker.remote_function INFO     Collecting pycryptodomex>=3.16.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,860 sagemaker.remote_function INFO       Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,961 sagemaker.remote_function INFO     Collecting pyzstd>=0.15.9 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:27,967 sagemaker.remote_function INFO       Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,051 sagemaker.remote_function INFO     Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,056 sagemaker.remote_function INFO       Downloading pyppmd-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,101 sagemaker.remote_function INFO     Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,105 sagemaker.remote_function INFO       Downloading pybcj-1.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,118 sagemaker.remote_function INFO     Collecting multivolumefile>=0.2.3 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,122 sagemaker.remote_function INFO       Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,170 sagemaker.remote_function INFO     Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,174 sagemaker.remote_function INFO       Downloading inflate64-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,178 sagemaker.remote_function INFO     Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 13)) (1.1.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,183 sagemaker.remote_function INFO     Requirement already satisfied: botocore<1.36.0,>=1.35.63 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (1.35.63)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,183 sagemaker.remote_function INFO     Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (1.0.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,184 sagemaker.remote_function INFO     Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.10.3)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,227 sagemaker.remote_function INFO     Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,231 sagemaker.remote_function INFO       Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,242 sagemaker.remote_function INFO     Collecting aiosignal>=1.1.2 (from aiohttp->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,245 sagemaker.remote_function INFO       Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,302 sagemaker.remote_function INFO     Collecting frozenlist>=1.1.1 (from aiohttp->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,306 sagemaker.remote_function INFO       Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,553 sagemaker.remote_function INFO     Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,558 sagemaker.remote_function INFO       Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,591 sagemaker.remote_function INFO     Collecting propcache>=0.2.0 (from aiohttp->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,595 sagemaker.remote_function INFO       Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,891 sagemaker.remote_function INFO     Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,896 sagemaker.remote_function INFO       Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,917 sagemaker.remote_function INFO     Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (4.12.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,921 sagemaker.remote_function INFO     Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (3.21.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,946 sagemaker.remote_function INFO     Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.4.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,946 sagemaker.remote_function INFO     Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.10)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:28,947 sagemaker.remote_function INFO     Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.47.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2024.8.30)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:29,479 sagemaker.remote_function INFO     Collecting boto3<2.0,>=1.34.142 (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:29,483 sagemaker.remote_function INFO       Downloading boto3-1.35.83-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:29,487 sagemaker.remote_function INFO     Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (2.9.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:29,487 sagemaker.remote_function INFO     Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (13.9.4)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:29,488 sagemaker.remote_function INFO     Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (4.0.3)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,004 sagemaker.remote_function INFO     Collecting botocore<1.36.0,>=1.35.83 (from boto3<2.0,>=1.34.142->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,008 sagemaker.remote_function INFO       Downloading botocore-1.35.83-py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,016 sagemaker.remote_function INFO     Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (2024.10.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,017 sagemaker.remote_function INFO     Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.35.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,017 sagemaker.remote_function INFO     Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.21.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,031 sagemaker.remote_function INFO     Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.13.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (3.4.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,031 sagemaker.remote_function INFO     Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.13.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (3.1.4)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,032 sagemaker.remote_function INFO     Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.13.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (1.13.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,034 sagemaker.remote_function INFO     Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.13.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,049 sagemaker.remote_function INFO     Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (1.16.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,059 sagemaker.remote_function INFO     Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (2.9.0.post0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,060 sagemaker.remote_function INFO     Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (2024.1)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,060 sagemaker.remote_function INFO     Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==3.1.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 5)) (2024.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,063 sagemaker.remote_function INFO     Requirement already satisfied: ppft>=1.7.6.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (1.7.6.9)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,066 sagemaker.remote_function INFO     INFO: pip is looking at multiple versions of pathos to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,075 sagemaker.remote_function INFO     Collecting pathos (from sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,079 sagemaker.remote_function INFO       Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,083 sagemaker.remote_function INFO     Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.3.5)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,130 sagemaker.remote_function INFO     Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.7.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,130 sagemaker.remote_function INFO     Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (2.23.4)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,141 sagemaker.remote_function INFO     Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (3.0.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,142 sagemaker.remote_function INFO     Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (2.18.0)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,281 sagemaker.remote_function INFO     Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft==0.13.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (3.0.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,291 sagemaker.remote_function INFO     Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.15->sagemaker==2.235.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 9)) (0.1.2)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,307 sagemaker.remote_function INFO     Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,439 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 82.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,445 sagemaker.remote_function INFO     Downloading peft-0.13.2-py3-none-any.whl (320 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,452 sagemaker.remote_function INFO     Downloading accelerate-1.1.0-py3-none-any.whl (333 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:30,460 sagemaker.remote_function INFO     Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,040 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.4/122.4 MB 211.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,046 sagemaker.remote_function INFO     Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,055 sagemaker.remote_function INFO     Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,062 sagemaker.remote_function INFO     Downloading hf_transfer-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,083 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 186.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,089 sagemaker.remote_function INFO     Downloading sagemaker-2.235.1-py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,100 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 149.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,107 sagemaker.remote_function INFO     Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,116 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 148.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,121 sagemaker.remote_function INFO     Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,138 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 184.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,142 sagemaker.remote_function INFO     Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,147 sagemaker.remote_function INFO     Downloading dill-0.3.8-py3-none-any.whl (116 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,153 sagemaker.remote_function INFO     Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,159 sagemaker.remote_function INFO     Downloading aiohttp-3.11.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,171 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 154.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,177 sagemaker.remote_function INFO     Downloading inflate64-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,182 sagemaker.remote_function INFO     Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,188 sagemaker.remote_function INFO     Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,194 sagemaker.remote_function INFO     Downloading pybcj-1.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,199 sagemaker.remote_function INFO     Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,214 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 170.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,219 sagemaker.remote_function INFO     Downloading pyppmd-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,227 sagemaker.remote_function INFO     Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,234 sagemaker.remote_function INFO     Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,242 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 792.7/792.7 kB 117.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,246 sagemaker.remote_function INFO     Downloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,252 sagemaker.remote_function INFO     Downloading sagemaker_core-1.0.17-py3-none-any.whl (403 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,259 sagemaker.remote_function INFO     Downloading boto3-1.35.83-py3-none-any.whl (139 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,265 sagemaker.remote_function INFO     Downloading pathos-0.3.2-py3-none-any.whl (82 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,270 sagemaker.remote_function INFO     Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,276 sagemaker.remote_function INFO     Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,282 sagemaker.remote_function INFO     Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,287 sagemaker.remote_function INFO     Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,293 sagemaker.remote_function INFO     Downloading botocore-1.35.83-py3-none-any.whl (13.3 MB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,360 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 202.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,364 sagemaker.remote_function INFO     Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,373 sagemaker.remote_function INFO     Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,379 sagemaker.remote_function INFO     Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,385 sagemaker.remote_function INFO     Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:31,901 sagemaker.remote_function INFO     Installing collected packages: texttable, sentencepiece, xxhash, regex, pyzstd, pyppmd, pycryptodomex, pybcj, propcache, multivolumefile, multidict, inflate64, hf-transfer, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, responses, py7zr, multiprocess, botocore, aiosignal, tokenizers, pathos, bitsandbytes, aiohttp, accelerate, transformers, boto3, sagemaker-core, peft, datasets, sagemaker, evaluate\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,637 sagemaker.remote_function INFO       Attempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,642 sagemaker.remote_function INFO         Found existing installation: fsspec 2024.10.0\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,649 sagemaker.remote_function INFO         Uninstalling fsspec-2024.10.0:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,671 sagemaker.remote_function INFO           Successfully uninstalled fsspec-2024.10.0\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,802 sagemaker.remote_function INFO       Attempting uninstall: dill\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,808 sagemaker.remote_function INFO         Found existing installation: dill 0.3.9\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,814 sagemaker.remote_function INFO         Uninstalling dill-0.3.9:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:32,836 sagemaker.remote_function INFO           Successfully uninstalled dill-0.3.9\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,016 sagemaker.remote_function INFO       Attempting uninstall: multiprocess\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,021 sagemaker.remote_function INFO         Found existing installation: multiprocess 0.70.17\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,028 sagemaker.remote_function INFO         Uninstalling multiprocess-0.70.17:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,053 sagemaker.remote_function INFO           Successfully uninstalled multiprocess-0.70.17\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,162 sagemaker.remote_function INFO       Attempting uninstall: botocore\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,166 sagemaker.remote_function INFO         Found existing installation: botocore 1.35.63\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,244 sagemaker.remote_function INFO         Uninstalling botocore-1.35.63:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:33,851 sagemaker.remote_function INFO           Successfully uninstalled botocore-1.35.63\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:34,553 sagemaker.remote_function INFO       Attempting uninstall: pathos\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:34,559 sagemaker.remote_function INFO         Found existing installation: pathos 0.3.3\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:34,565 sagemaker.remote_function INFO         Uninstalling pathos-0.3.3:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:34,586 sagemaker.remote_function INFO           Successfully uninstalled pathos-0.3.3\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:36,478 sagemaker.remote_function INFO       Attempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:36,485 sagemaker.remote_function INFO         Found existing installation: accelerate 1.1.1\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:36,495 sagemaker.remote_function INFO         Uninstalling accelerate-1.1.1:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:36,533 sagemaker.remote_function INFO           Successfully uninstalled accelerate-1.1.1\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,536 sagemaker.remote_function INFO       Attempting uninstall: boto3\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,540 sagemaker.remote_function INFO         Found existing installation: boto3 1.35.63\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,547 sagemaker.remote_function INFO         Uninstalling boto3-1.35.63:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,576 sagemaker.remote_function INFO           Successfully uninstalled boto3-1.35.63\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,635 sagemaker.remote_function INFO       Attempting uninstall: sagemaker-core\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,641 sagemaker.remote_function INFO         Found existing installation: sagemaker-core 1.0.14\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,645 sagemaker.remote_function INFO         Uninstalling sagemaker-core-1.0.14:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:41,664 sagemaker.remote_function INFO           Successfully uninstalled sagemaker-core-1.0.14\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:42,322 sagemaker.remote_function INFO       Attempting uninstall: sagemaker\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:42,329 sagemaker.remote_function INFO         Found existing installation: sagemaker 2.233.0\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:42,383 sagemaker.remote_function INFO         Uninstalling sagemaker-2.233.0:\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:42,607 sagemaker.remote_function INFO           Successfully uninstalled sagemaker-2.233.0\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:43,371 sagemaker.remote_function INFO     Successfully installed accelerate-1.1.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.2 bitsandbytes-0.44.1 boto3-1.35.83 botocore-1.35.83 datasets-3.1.0 dill-0.3.8 evaluate-0.4.1 frozenlist-1.5.0 fsspec-2024.9.0 hf-transfer-0.1.8 inflate64-1.0.0 multidict-6.1.0 multiprocess-0.70.16 multivolumefile-0.2.3 pathos-0.3.2 peft-0.13.2 propcache-0.2.1 py7zr-0.22.0 pybcj-1.0.2 pycryptodomex-3.21.0 pyppmd-1.1.0 pyzstd-0.16.2 regex-2024.11.6 responses-0.18.0 sagemaker-2.235.1 sagemaker-core-1.0.17 sentencepiece-0.2.0 texttable-1.7.0 tokenizers-0.21.0 transformers-4.47.1 xxhash-3.5.0 yarl-1.18.3\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:44,225 sagemaker.remote_function ERROR    ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:44,225 sagemaker.remote_function WARNING  awscli 1.36.4 requires botocore==1.35.63, but you have botocore 1.35.83 which is incompatible.\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:44,225 sagemaker.remote_function WARNING  WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:44,225 sagemaker.remote_function INFO     Command /opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U ran successfully\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34mINFO: Changing workspace to sagemaker_remote_function_workspace.\u001b[0m\n",
      "\u001b[34mINFO: No conda env provided. Invoking remote function with torchrun\u001b[0m\n",
      "\u001b[34mW1218 09:40:48.095000 78 site-packages/torch/distributed/run.py:793] \u001b[0m\n",
      "\u001b[34mW1218 09:40:48.095000 78 site-packages/torch/distributed/run.py:793] *****************************************\u001b[0m\n",
      "\u001b[34mW1218 09:40:48.095000 78 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34mW1218 09:40:48.095000 78 site-packages/torch/distributed/run.py:793] *****************************************\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:50,264 sagemaker.remote_function INFO     Deserializing function code from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/function\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:50,264 sagemaker.remote_function INFO     Deserializing function code from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/function\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:50,287 sagemaker.remote_function INFO     Deserializing function code from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/function\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:50,290 sagemaker.remote_function INFO     Deserializing function code from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/function\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:53,709 sagemaker.remote_function INFO     Deserializing function arguments from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/arguments\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:53,709 sagemaker.remote_function INFO     Deserializing function arguments from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/arguments\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:53,709 sagemaker.remote_function INFO     Deserializing function arguments from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/arguments\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:53,709 sagemaker.remote_function INFO     Deserializing function arguments from s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/arguments\u001b[0m\n",
      "\u001b[34m[12/18/24 09:40:53] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m[12/18/24 09:40:53] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m[12/18/24 09:40:53] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m[12/18/24 09:40:53] INFO     PyTorch version 2.5.1+cu124 available. config.py:54\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,035 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,035 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,035 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,035 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,036 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,036 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,036 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34m2024-12-18 09:40:54,036 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:130 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:130 [0] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:130 [0] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:130 [0] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:133 [3] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:133 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:133 [3] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:133 [3] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:131 [1] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:131 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:131 [1] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:131 [1] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:132 [2] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:132 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^docker0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:132 [2] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:132 [2] NCCL INFO NCCL version 2.23.4+cuda12.4\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.12.1-aws\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Using Libfabric version 1.22\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Setting provider_filter to efa\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Internode latency set at 150.0 us\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Creating one domain per process\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Setting NCCL_PROTO to \"simple\"\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO ncclCommInitRankConfig comm 0x564ba461efe0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1b0 commId 0x8f29387a97375678 - Init START\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Setting NCCL_PROTO to \"simple\"\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Setting NCCL_PROTO to \"simple\"\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Setting NCCL_PROTO to \"simple\"\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO ncclCommInitRankConfig comm 0x55582f8cfc20 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 1e0 commId 0x8f29387a97375678 - Init START\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO ncclCommInitRankConfig comm 0x5651e1f48220 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 1d0 commId 0x8f29387a97375678 - Init START\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO ncclCommInitRankConfig comm 0x5614653e7080 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 1c0 commId 0x8f29387a97375678 - Init START\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO Bootstrap timings total 0.000783 (create 0.000033, send 0.000138, recv 0.000104, ring 0.000254, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO Bootstrap timings total 0.000609 (create 0.000029, send 0.000120, recv 0.000259, ring 0.000063, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO Bootstrap timings total 0.000676 (create 0.000030, send 0.000106, recv 0.000160, ring 0.000075, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Bootstrap timings total 0.064138 (create 0.000030, send 0.000136, recv 0.063727, ring 0.000074, delay 0.000000)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NET/OFI Global registrations supported\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO comm 0x5614653e7080 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO comm 0x564ba461efe0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO comm 0x5651e1f48220 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO comm 0x55582f8cfc20 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Channel 00/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Channel 01/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Channel 02/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Channel 03/04 : 0 1 2 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:216 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:213 [3] NCCL INFO [Proxy Service] Device 3 CPU core 18\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:214 [1] NCCL INFO [Proxy Service] Device 1 CPU core 43\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:219 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:218 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 38\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:217 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 44\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:220 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 12\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:215 [2] NCCL INFO [Proxy Service] Device 2 CPU core 13\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO CC Off, Multi-GPU CC Off, workFifoBytes 1048576\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO ncclCommInitRankConfig comm 0x5614653e7080 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 1c0 commId 0x8f29387a97375678 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO ncclCommInitRankConfig comm 0x5651e1f48220 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 1d0 commId 0x8f29387a97375678 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO ncclCommInitRankConfig comm 0x55582f8cfc20 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId 1e0 commId 0x8f29387a97375678 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO ncclCommInitRankConfig comm 0x564ba461efe0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1b0 commId 0x8f29387a97375678 - Init COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:211 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.23 (kernels 0.13, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:212 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.23 (kernels 0.13, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:210 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.23 (kernels 0.13, alloc 0.08, bootstrap 0.00, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:209 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.23 (kernels 0.13, alloc 0.02, bootstrap 0.06, allgathers 0.00, topo 0.01, graphs 0.00, connections 0.01, rest 0.00)\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:223 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:223 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:223 [0] NCCL INFO Channel 02 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:223 [0] NCCL INFO Channel 03 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 01 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 02 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 02 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 03 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 03 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:224 [3] NCCL INFO Channel 00 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:224 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:224 [3] NCCL INFO Channel 02 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:224 [3] NCCL INFO Channel 03 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 02 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 02 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Channel 03 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Channel 03 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:223 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:224 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:222 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:221 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m#015Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]#015Fetching 12 files:   8%|▊         | 1/12 [00:00<00:01,  7.60it/s]#015Fetching 12 files:  42%|████▏     | 5/12 [07:55<11:47, 101.08s/it]#015Fetching 12 files: 100%|██████████| 12/12 [07:55<00:00, 39.60s/it]\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 900\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/900 [00:00<?, ? examples/s]#015Map:  15%|█▌        | 137/900 [00:00<00:00, 1354.19 examples/s]#015Map:  38%|███▊      | 338/900 [00:00<00:00, 1339.18 examples/s]#015Map:  53%|█████▎    | 473/900 [00:00<00:00, 1341.62 examples/s]#015Map:  68%|██████▊   | 611/900 [00:00<00:00, 1352.55 examples/s]#015Map:  83%|████████▎ | 747/900 [00:00<00:00, 1349.09 examples/s]#015Map:  99%|█████████▊| 887/900 [00:00<00:00, 1361.11 examples/s]#015Map: 100%|██████████| 900/900 [00:00<00:00, 1259.49 examples/s]\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/100 [00:00<?, ? examples/s]#015Map: 100%|██████████| 100/100 [00:00<00:00, 1216.51 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 100\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/900 [00:00<?, ? examples/s]#015Map:   0%|          | 0/900 [00:00<?, ? examples/s]#015Map:   0%|          | 0/900 [00:00<?, ? examples/s]`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 900\u001b[0m\n",
      "\u001b[34m#015Map:  15%|█▌        | 137/900 [00:00<00:00, 1357.44 examples/s]#015Map:  15%|█▌        | 137/900 [00:00<00:00, 1354.81 examples/s]#015Map:  15%|█▌        | 138/900 [00:00<00:00, 1361.23 examples/s]#015Map:  38%|███▊      | 340/900 [00:00<00:00, 1347.04 examples/s]#015Map:  38%|███▊      | 339/900 [00:00<00:00, 1341.69 examples/s]#015Map:  38%|███▊      | 340/900 [00:00<00:00, 1346.64 examples/s]#015Map:  53%|█████▎    | 477/900 [00:00<00:00, 1351.00 examples/s]#015Map:  53%|█████▎    | 476/900 [00:00<00:00, 1346.89 examples/s]#015Map:  53%|█████▎    | 475/900 [00:00<00:00, 1345.35 examples/s]#015Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]#015Map:  69%|██████▊   | 617/900 [00:00<00:00, 1363.86 examples/s]#015Map:  68%|██████▊   | 616/900 [00:00<00:00, 1362.37 examples/s]#015Map:  68%|██████▊   | 614/900 [00:00<00:00, 1356.85 examples/s]#015Map:  84%|████████▍ | 756/900 [00:00<00:00, 1368.69 examples/s]#015Map:  84%|████████▍ | 757/900 [00:00<00:00, 1368.08 examples/s]#015Map:  84%|████████▎ | 752/900 [00:00<00:00, 1362.61 examples/s]#015Map: 100%|█████████▉| 899/900 [00:00<00:00, 1382.19 examples/s]#015Map: 100%|█████████▉| 898/900 [00:00<00:00, 1380.56 examples/s]#015Map:  99%|█████████▉| 894/900 [00:00<00:00, 1378.34 examples/s]#015Map: 100%|██████████| 900/900 [00:00<00:00, 1268.94 examples/s]\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 900/900 [00:00<00:00, 1265.08 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 900\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 900\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 900/900 [00:00<00:00, 1270.01 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 100\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/100 [00:00<?, ? examples/s]#015Map:   0%|          | 0/100 [00:00<?, ? examples/s]#015Map:   0%|          | 0/100 [00:00<?, ? examples/s]#015Map: 100%|██████████| 100/100 [00:00<00:00, 1240.28 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 100\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 100/100 [00:00<00:00, 1226.75 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of test samples: 100\u001b[0m\n",
      "\u001b[34m#015Map: 100%|██████████| 100/100 [00:00<00:00, 1246.62 examples/s]\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34m`low_cpu_mem_usage` was None, now default to True since model is quantized.\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]#015Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]#015Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]#015Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.15s/it]#015Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.70s/it]#015Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.70s/it]#015Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.69s/it]#015Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.18s/it]#015Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.71s/it]#015Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.71s/it]#015Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.70s/it]#015Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.85s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.37s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.98s/it]\u001b[0m\n",
      "\u001b[34mtrainable params: 22134784 || all params: 4152650752 || trainable%: 0.5330278254037965\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.33s/it]#015Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.33s/it]#015Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.33s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  3.67s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.35s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  3.67s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.35s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  3.67s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.35s/it]\u001b[0m\n",
      "\u001b[34mtrainable params: 22134784 || all params: 4152650752 || trainable%: 0.5330278254037965\u001b[0m\n",
      "\u001b[34mtrainable params: 22134784 || all params: 4152650752 || trainable%: 0.5330278254037965\u001b[0m\n",
      "\u001b[34mtrainable params: 22134784 || all params: 4152650752 || trainable%: 0.5330278254037965\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:443 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:444 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:445 [3] NCCL INFO Channel 00 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:445 [3] NCCL INFO Channel 01 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:445 [3] NCCL INFO Channel 02 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:445 [3] NCCL INFO Channel 03 : 3[3] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:439 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:445 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/112 [00:00<?, ?it/s]The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34m{'loss': 2.3608, 'grad_norm': 0.40125349164009094, 'learning_rate': 0.00019821428571428572, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m{'loss': 2.4376, 'grad_norm': 0.43071988224983215, 'learning_rate': 0.00019642857142857144, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m{'loss': 2.5586, 'grad_norm': 0.6493661999702454, 'learning_rate': 0.00019464285714285715, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34m{'loss': 2.223, 'grad_norm': 0.5438141226768494, 'learning_rate': 0.00019285714285714286, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34m{'loss': 2.035, 'grad_norm': 0.45938658714294434, 'learning_rate': 0.00019107142857142858, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m{'loss': 2.0427, 'grad_norm': 0.3527636229991913, 'learning_rate': 0.0001892857142857143, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34m{'loss': 1.9942, 'grad_norm': 0.3773604929447174, 'learning_rate': 0.0001875, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6963, 'grad_norm': 0.35121262073516846, 'learning_rate': 0.00018571428571428572, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7047, 'grad_norm': 0.3816111385822296, 'learning_rate': 0.00018392857142857143, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m{'loss': 1.92, 'grad_norm': 0.38999131321907043, 'learning_rate': 0.00018214285714285714, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m{'loss': 2.074, 'grad_norm': 0.3454204499721527, 'learning_rate': 0.00018035714285714286, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m{'loss': 1.9417, 'grad_norm': 0.306200236082077, 'learning_rate': 0.0001785714285714286, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m{'loss': 1.9057, 'grad_norm': 0.28250381350517273, 'learning_rate': 0.00017678571428571428, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8285, 'grad_norm': 0.25015243887901306, 'learning_rate': 0.000175, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7931, 'grad_norm': 0.32091382145881653, 'learning_rate': 0.00017321428571428574, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m{'loss': 1.9261, 'grad_norm': 0.3082287609577179, 'learning_rate': 0.00017142857142857143, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8212, 'grad_norm': 0.2638015151023865, 'learning_rate': 0.00016964285714285714, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7468, 'grad_norm': 0.41521143913269043, 'learning_rate': 0.00016785714285714288, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7434, 'grad_norm': 0.6615378260612488, 'learning_rate': 0.0001660714285714286, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8335, 'grad_norm': 0.30027326941490173, 'learning_rate': 0.00016428571428571428, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34m{'loss': 1.9223, 'grad_norm': 0.3032633364200592, 'learning_rate': 0.00016250000000000002, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6414, 'grad_norm': 0.3876338601112366, 'learning_rate': 0.00016071428571428573, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6528, 'grad_norm': 0.34014955163002014, 'learning_rate': 0.00015892857142857142, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6807, 'grad_norm': 0.2903609275817871, 'learning_rate': 0.00015714285714285716, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7063, 'grad_norm': 0.29998138546943665, 'learning_rate': 0.00015535714285714287, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6294, 'grad_norm': 0.28216370940208435, 'learning_rate': 0.0001535714285714286, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7895, 'grad_norm': 0.3254387676715851, 'learning_rate': 0.00015178571428571427, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34m{'loss': 1.8721, 'grad_norm': 0.2850405275821686, 'learning_rate': 0.00015000000000000001, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4772, 'grad_norm': 0.27757641673088074, 'learning_rate': 0.00014821428571428573, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5971, 'grad_norm': 0.2676663398742676, 'learning_rate': 0.00014642857142857141, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7174, 'grad_norm': 0.3241122364997864, 'learning_rate': 0.00014464285714285715, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m{'loss': 1.738, 'grad_norm': 0.27560022473335266, 'learning_rate': 0.00014285714285714287, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4498, 'grad_norm': 0.2845272123813629, 'learning_rate': 0.00014107142857142858, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7503, 'grad_norm': 0.2953305244445801, 'learning_rate': 0.0001392857142857143, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m{'loss': 1.7162, 'grad_norm': 0.2740831971168518, 'learning_rate': 0.0001375, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6638, 'grad_norm': 0.2646324932575226, 'learning_rate': 0.00013571428571428572, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6211, 'grad_norm': 0.2827402651309967, 'learning_rate': 0.00013392857142857144, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5839, 'grad_norm': 0.2672780752182007, 'learning_rate': 0.00013214285714285715, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5988, 'grad_norm': 0.31376972794532776, 'learning_rate': 0.00013035714285714286, 'epoch': 0.69}\u001b[0m\n",
      "\u001b[34m{'loss': 1.434, 'grad_norm': 0.26940056681632996, 'learning_rate': 0.00012857142857142858, 'epoch': 0.71}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5126, 'grad_norm': 0.3436448872089386, 'learning_rate': 0.0001267857142857143, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m{'loss': 1.6281, 'grad_norm': 0.3714866638183594, 'learning_rate': 0.000125, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4202, 'grad_norm': 0.37208443880081177, 'learning_rate': 0.00012321428571428572, 'epoch': 0.76}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5457, 'grad_norm': 0.38318678736686707, 'learning_rate': 0.00012142857142857143, 'epoch': 0.78}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5383, 'grad_norm': 0.3661890923976898, 'learning_rate': 0.00011964285714285714, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4061, 'grad_norm': 0.36864909529685974, 'learning_rate': 0.00011785714285714287, 'epoch': 0.81}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1829, 'grad_norm': 0.4005148708820343, 'learning_rate': 0.00011607142857142858, 'epoch': 0.83}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5425, 'grad_norm': 0.3955934941768646, 'learning_rate': 0.00011428571428571428, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5035, 'grad_norm': 0.40292808413505554, 'learning_rate': 0.00011250000000000001, 'epoch': 0.87}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4317, 'grad_norm': 0.3826664686203003, 'learning_rate': 0.00011071428571428572, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4033, 'grad_norm': 0.3986109495162964, 'learning_rate': 0.00010892857142857142, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m{'loss': 1.5597, 'grad_norm': 0.39693161845207214, 'learning_rate': 0.00010714285714285715, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4313, 'grad_norm': 0.3564304709434509, 'learning_rate': 0.00010535714285714286, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1956, 'grad_norm': 0.43857744336128235, 'learning_rate': 0.00010357142857142859, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1958, 'grad_norm': 0.5224201679229736, 'learning_rate': 0.00010178571428571428, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[34m{'loss': 1.3924, 'grad_norm': 0.41958701610565186, 'learning_rate': 0.0001, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4422, 'grad_norm': 0.5910346508026123, 'learning_rate': 9.821428571428572e-05, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'loss': 1.071, 'grad_norm': 0.49908941984176636, 'learning_rate': 9.642857142857143e-05, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9429, 'grad_norm': 0.5807231664657593, 'learning_rate': 9.464285714285715e-05, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1489, 'grad_norm': 0.48687154054641724, 'learning_rate': 9.285714285714286e-05, 'epoch': 1.05}\u001b[0m\n",
      "\u001b[34m{'loss': 1.3661, 'grad_norm': 0.4499427378177643, 'learning_rate': 9.107142857142857e-05, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9093, 'grad_norm': 0.5530925393104553, 'learning_rate': 8.92857142857143e-05, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0492, 'grad_norm': 0.7328051328659058, 'learning_rate': 8.75e-05, 'epoch': 1.11}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1126, 'grad_norm': 0.5211970806121826, 'learning_rate': 8.571428571428571e-05, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9951, 'grad_norm': 0.533788800239563, 'learning_rate': 8.392857142857144e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1562, 'grad_norm': 0.6470096707344055, 'learning_rate': 8.214285714285714e-05, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9582, 'grad_norm': 0.6909326314926147, 'learning_rate': 8.035714285714287e-05, 'epoch': 1.18}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1476, 'grad_norm': 0.5452954769134521, 'learning_rate': 7.857142857142858e-05, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2646, 'grad_norm': 0.6648005247116089, 'learning_rate': 7.67857142857143e-05, 'epoch': 1.21}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0471, 'grad_norm': 0.623548686504364, 'learning_rate': 7.500000000000001e-05, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9996, 'grad_norm': 0.6123811602592468, 'learning_rate': 7.321428571428571e-05, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2225, 'grad_norm': 0.6340981125831604, 'learning_rate': 7.142857142857143e-05, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8016, 'grad_norm': 0.6303067207336426, 'learning_rate': 6.964285714285715e-05, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m{'loss': 1.0546, 'grad_norm': 0.5985935926437378, 'learning_rate': 6.785714285714286e-05, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1195, 'grad_norm': 0.6477797031402588, 'learning_rate': 6.607142857142857e-05, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9284, 'grad_norm': 0.6365825533866882, 'learning_rate': 6.428571428571429e-05, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m{'loss': 1.2553, 'grad_norm': 0.610120415687561, 'learning_rate': 6.25e-05, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4228, 'grad_norm': 0.5669413805007935, 'learning_rate': 6.0714285714285715e-05, 'epoch': 1.37}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7883, 'grad_norm': 0.6372789144515991, 'learning_rate': 5.8928571428571435e-05, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8614, 'grad_norm': 0.5253504514694214, 'learning_rate': 5.714285714285714e-05, 'epoch': 1.41}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1701, 'grad_norm': 0.6875113844871521, 'learning_rate': 5.535714285714286e-05, 'epoch': 1.42}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7432, 'grad_norm': 0.5526481866836548, 'learning_rate': 5.3571428571428575e-05, 'epoch': 1.44}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9072, 'grad_norm': 0.8502063155174255, 'learning_rate': 5.1785714285714296e-05, 'epoch': 1.46}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7653, 'grad_norm': 0.8050635457038879, 'learning_rate': 5e-05, 'epoch': 1.48}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7959, 'grad_norm': 0.8318017721176147, 'learning_rate': 4.8214285714285716e-05, 'epoch': 1.5}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7773, 'grad_norm': 0.693027675151825, 'learning_rate': 4.642857142857143e-05, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7352, 'grad_norm': 0.8120520114898682, 'learning_rate': 4.464285714285715e-05, 'epoch': 1.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7219, 'grad_norm': 0.6033027768135071, 'learning_rate': 4.2857142857142856e-05, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8356, 'grad_norm': 0.6497929692268372, 'learning_rate': 4.107142857142857e-05, 'epoch': 1.57}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7622, 'grad_norm': 0.714063823223114, 'learning_rate': 3.928571428571429e-05, 'epoch': 1.58}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7259, 'grad_norm': 0.721764326095581, 'learning_rate': 3.7500000000000003e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9253, 'grad_norm': 0.7040921449661255, 'learning_rate': 3.571428571428572e-05, 'epoch': 1.62}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9385, 'grad_norm': 0.599907398223877, 'learning_rate': 3.392857142857143e-05, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6176, 'grad_norm': 0.6645664572715759, 'learning_rate': 3.2142857142857144e-05, 'epoch': 1.65}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8568, 'grad_norm': 0.734487771987915, 'learning_rate': 3.0357142857142857e-05, 'epoch': 1.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7519, 'grad_norm': 0.5864545702934265, 'learning_rate': 2.857142857142857e-05, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7607, 'grad_norm': 0.5724912881851196, 'learning_rate': 2.6785714285714288e-05, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6951, 'grad_norm': 0.6336464285850525, 'learning_rate': 2.5e-05, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m#015  1%|          | 1/112 [00:03<06:07,  3.31s/it]#015                                               #015#015  1%|          | 1/112 [00:03<06:07,  3.31s/it]#015  2%|▏         | 2/112 [00:06<06:18,  3.44s/it]#015                                               #015#015  2%|▏         | 2/112 [00:06<06:18,  3.44s/it]#015  3%|▎         | 3/112 [00:09<05:53,  3.25s/it]#015                                               #015#015  3%|▎         | 3/112 [00:09<05:53,  3.25s/it]#015  4%|▎         | 4/112 [00:12<05:45,  3.20s/it]#015                                               #015#015  4%|▎         | 4/112 [00:13<05:45,  3.20s/it]#015  4%|▍         | 5/112 [00:16<06:02,  3.39s/it]#015                                               #015#015  4%|▍         | 5/112 [00:16<06:02,  3.39s/it]#015  5%|▌         | 6/112 [00:20<06:01,  3.41s/it]#015                                               #015#015  5%|▌         | 6/112 [00:20<06:01,  3.41s/it]#015  6%|▋         | 7/112 [00:23<05:42,  3.26s/it]#015                                               #015#015  6%|▋         | 7/112 [00:23<05:42,  3.26s/it]#015  7%|▋         | 8/112 [00:26<05:35,  3.23s/it]#015                                               #015#015  7%|▋         | 8/112 [00:26<05:35,  3.23s/it]#015  8%|▊         | 9/112 [00:29<05:21,  3.12s/it]#015                                               #015#015  8%|▊         | 9/112 [00:29<05:21,  3.12s/it]#015  9%|▉         | 10/112 [00:32<05:15,  3.10s/it]#015                                                #015#015  9%|▉         | 10/112 [00:32<05:15,  3.10s/it]#015 10%|▉         | 11/112 [00:35<05:14,  3.11s/it]#015                                                #015#015 10%|▉         | 11/112 [00:35<05:14,  3.11s/it]#015 11%|█         | 12/112 [00:38<05:12,  3.12s/it]#015                                                #015#015 11%|█         | 12/112 [00:38<05:12,  3.12s/it]#015 12%|█▏        | 13/112 [00:41<05:01,  3.05s/it]#015                                                #015#015 12%|█▏        | 13/112 [00:41<05:01,  3.05s/it]#015 12%|█▎        | 14/112 [00:44<05:10,  3.17s/it]#015                                                #015#015 12%|█▎        | 14/112 [00:44<05:10,  3.17s/it]#015 13%|█▎        | 15/112 [00:47<04:58,  3.08s/it]#015                                                #015#015 13%|█▎        | 15/112 [00:47<04:58,  3.08s/it]#015 14%|█▍        | 16/112 [00:51<05:16,  3.30s/it]#015                                                #015#015 14%|█▍        | 16/112 [00:51<05:16,  3.30s/it]#015 15%|█▌        | 17/112 [00:54<05:08,  3.25s/it]#015                                                #015#015 15%|█▌        | 17/112 [00:54<05:08,  3.25s/it]#015 16%|█▌        | 18/112 [00:57<05:08,  3.28s/it]#015                                                #015#015 16%|█▌        | 18/112 [00:57<05:08,  3.28s/it]#015 17%|█▋        | 19/112 [01:01<05:06,  3.29s/it]#015                                                #015#015 17%|█▋        | 19/112 [01:01<05:06,  3.29s/it]#015 18%|█▊        | 20/112 [01:05<05:14,  3.42s/it]#015                                                #015#015 18%|█▊        | 20/112 [01:05<05:14,  3.42s/it]#015 19%|█▉        | 21/112 [01:08<05:11,  3.43s/it]#015                                                #015#015 19%|█▉        | 21/112 [01:08<05:11,  3.43s/it]#015 20%|█▉        | 22/112 [01:11<05:03,  3.38s/it]#015                                                #015#015 20%|█▉        | 22/112 [01:11<05:03,  3.38s/it]#015 21%|██        | 23/112 [01:15<05:02,  3.39s/it]#015                                                #015#015 21%|██        | 23/112 [01:15<05:02,  3.39s/it]#015 21%|██▏       | 24/112 [01:18<05:10,  3.53s/it]#015                                                #015#015 21%|██▏       | 24/112 [01:19<05:10,  3.53s/it]#015 22%|██▏       | 25/112 [01:22<04:54,  3.38s/it]#015                                                #015#015 22%|██▏       | 25/112 [01:22<04:54,  3.38s/it]#015 23%|██▎       | 26/112 [01:24<04:37,  3.23s/it]#015                                                #015#015 23%|██▎       | 26/112 [01:24<04:37,  3.23s/it]#015 24%|██▍       | 27/112 [01:27<04:21,  3.08s/it]#015                                                #015#015 24%|██▍       | 27/112 [01:27<04:21,  3.08s/it]#015 25%|██▌       | 28/112 [01:30<04:13,  3.02s/it]#015                                                #015#015 25%|██▌       | 28/112 [01:30<04:13,  3.02s/it]#015 26%|██▌       | 29/112 [01:33<04:14,  3.06s/it]#015                                                #015#015 26%|██▌       | 29/112 [01:33<04:14,  3.06s/it]#015 27%|██▋       | 30/112 [01:36<04:13,  3.10s/it]#015                                                #015#015 27%|██▋       | 30/112 [01:36<04:13,  3.10s/it]#015 28%|██▊       | 31/112 [01:39<04:01,  2.98s/it]#015                                                #015#015 28%|██▊       | 31/112 [01:39<04:01,  2.98s/it]#015 29%|██▊       | 32/112 [01:42<03:56,  2.95s/it]#015                                                #015#015 29%|██▊       | 32/112 [01:42<03:56,  2.95s/it]#015 29%|██▉       | 33/112 [01:45<03:53,  2.96s/it]#015                                                #015#015 29%|██▉       | 33/112 [01:45<03:53,  2.96s/it]#015 30%|███       | 34/112 [01:48<03:57,  3.05s/it]#015                                                #015#015 30%|███       | 34/112 [01:48<03:57,  3.05s/it]#015 31%|███▏      | 35/112 [01:52<04:04,  3.18s/it]#015                                                #015#015 31%|███▏      | 35/112 [01:52<04:04,  3.18s/it]#015 32%|███▏      | 36/112 [01:55<04:04,  3.21s/it]#015                                                #015#015 32%|███▏      | 36/112 [01:55<04:04,  3.21s/it]#015 33%|███▎      | 37/112 [01:58<04:05,  3.27s/it]#015                                                #015#015 33%|███▎      | 37/112 [01:58<04:05,  3.27s/it]#015 34%|███▍      | 38/112 [02:02<04:07,  3.35s/it]#015                                                #015#015 34%|███▍      | 38/112 [02:02<04:07,  3.35s/it]#015 35%|███▍      | 39/112 [02:05<04:02,  3.32s/it]#015                                                #015#015 35%|███▍      | 39/112 [02:05<04:02,  3.32s/it]#015 36%|███▌      | 40/112 [02:09<04:18,  3.59s/it]#015                                                #015#015 36%|███▌      | 40/112 [02:09<04:18,  3.59s/it]#015 37%|███▋      | 41/112 [02:13<04:05,  3.46s/it]#015                                                #015#015 37%|███▋      | 41/112 [02:13<04:05,  3.46s/it]#015 38%|███▊      | 42/112 [02:16<03:52,  3.33s/it]#015                                                #015#015 38%|███▊      | 42/112 [02:16<03:52,  3.33s/it]#015 38%|███▊      | 43/112 [02:18<03:40,  3.20s/it]#015                                                #015#015 38%|███▊      | 43/112 [02:18<03:40,  3.20s/it]#015 39%|███▉      | 44/112 [02:22<03:47,  3.34s/it]#015                                                #015#015 39%|███▉      | 44/112 [02:22<03:47,  3.34s/it]#015 40%|████      | 45/112 [02:25<03:37,  3.25s/it]#015                                                #015#015 40%|████      | 45/112 [02:25<03:37,  3.25s/it]#015 41%|████      | 46/112 [02:28<03:35,  3.26s/it]#015                                                #015#015 41%|████      | 46/112 [02:28<03:35,  3.26s/it]#015 42%|████▏     | 47/112 [02:31<03:26,  3.17s/it]#015                                                #015#015 42%|████▏     | 47/112 [02:31<03:26,  3.17s/it]#015 43%|████▎     | 48/112 [02:35<03:29,  3.27s/it]#015                                                #015#015 43%|████▎     | 48/112 [02:35<03:29,  3.27s/it]#015 44%|████▍     | 49/112 [02:38<03:19,  3.17s/it]#015                                                #015#015 44%|████▍     | 49/112 [02:38<03:19,  3.17s/it]#015 45%|████▍     | 50/112 [02:41<03:22,  3.26s/it]#015                                                #015#015 45%|████▍     | 50/112 [02:41<03:22,  3.26s/it]#015 46%|████▌     | 51/112 [02:45<03:21,  3.30s/it]#015                                                #015#015 46%|████▌     | 51/112 [02:45<03:21,  3.30s/it]#015 46%|████▋     | 52/112 [02:48<03:09,  3.17s/it]#015                                                #015#015 46%|████▋     | 52/112 [02:48<03:09,  3.17s/it]#015 47%|████▋     | 53/112 [02:51<03:11,  3.25s/it]#015                                                #015#015 47%|████▋     | 53/112 [02:51<03:11,  3.25s/it]#015 48%|████▊     | 54/112 [02:54<02:59,  3.10s/it]#015                                                #015#015 48%|████▊     | 54/112 [02:54<02:59,  3.10s/it]#015 49%|████▉     | 55/112 [02:57<02:59,  3.16s/it]#015                                                #015#015 49%|████▉     | 55/112 [02:57<02:59,  3.16s/it]#015 50%|█████     | 56/112 [03:00<02:57,  3.17s/it]#015                                                #015#015 50%|█████     | 56/112 [03:00<02:57,  3.17s/it]#015 51%|█████     | 57/112 [03:02<02:28,  2.71s/it]#015                                                #015#015 51%|█████     | 57/112 [03:02<02:28,  2.71s/it]#015 52%|█████▏    | 58/112 [03:05<02:38,  2.93s/it]#015                                                #015#015 52%|█████▏    | 58/112 [03:05<02:38,  2.93s/it]#015 53%|█████▎    | 59/112 [03:08<02:37,  2.98s/it]#015                                                #015#015 53%|█████▎    | 59/112 [03:08<02:37,  2.98s/it]#015 54%|█████▎    | 60/112 [03:12<02:46,  3.20s/it]#015                                                #015#015 54%|█████▎    | 60/112 [03:12<02:46,  3.20s/it]#015 54%|█████▍    | 61/112 [03:15<02:38,  3.11s/it]#015                                                #015#015 54%|█████▍    | 61/112 [03:15<02:38,  3.11s/it]#015 55%|█████▌    | 62/112 [03:18<02:32,  3.05s/it]#015                                                #015#015 55%|█████▌    | 62/112 [03:18<02:32,  3.05s/it]#015 56%|█████▋    | 63/112 [03:21<02:27,  3.00s/it]#015                                                #015#015 56%|█████▋    | 63/112 [03:21<02:27,  3.00s/it]#015 57%|█████▋    | 64/112 [03:24<02:27,  3.07s/it]#015                                                #015#015 57%|█████▋    | 64/112 [03:24<02:27,  3.07s/it]#015 58%|█████▊    | 65/112 [03:27<02:21,  3.02s/it]#015                                                #015#015 58%|█████▊    | 65/112 [03:27<02:21,  3.02s/it]#015 59%|█████▉    | 66/112 [03:30<02:18,  3.02s/it]#015                                                #015#015 59%|█████▉    | 66/112 [03:30<02:18,  3.02s/it]#015 60%|█████▉    | 67/112 [03:34<02:26,  3.25s/it]#015                                                #015#015 60%|█████▉    | 67/112 [03:34<02:26,  3.25s/it]#015 61%|██████    | 68/112 [03:37<02:20,  3.19s/it]#015                                                #015#015 61%|██████    | 68/112 [03:37<02:20,  3.19s/it]#015 62%|██████▏   | 69/112 [03:40<02:16,  3.18s/it]#015                                                #015#015 62%|██████▏   | 69/112 [03:40<02:16,  3.18s/it]#015 62%|██████▎   | 70/112 [03:44<02:21,  3.37s/it]#015                                                #015#015 62%|██████▎   | 70/112 [03:44<02:21,  3.37s/it]#015 63%|██████▎   | 71/112 [03:47<02:13,  3.25s/it]#015                                                #015#015 63%|██████▎   | 71/112 [03:47<02:13,  3.25s/it]#015 64%|██████▍   | 72/112 [03:50<02:05,  3.15s/it]#015                                                #015#015 64%|██████▍   | 72/112 [03:50<02:05,  3.15s/it]#015 65%|██████▌   | 73/112 [03:53<02:08,  3.30s/it]#015                                                #015#015 65%|██████▌   | 73/112 [03:53<02:08,  3.30s/it]#015 66%|██████▌   | 74/112 [03:56<02:01,  3.21s/it]#015                                                #015#015 66%|██████▌   | 74/112 [03:56<02:01,  3.21s/it]#015 67%|██████▋   | 75/112 [04:00<02:01,  3.27s/it]#015                                                #015#015 67%|██████▋   | 75/112 [04:00<02:01,  3.27s/it]#015 68%|██████▊   | 76/112 [04:03<01:55,  3.20s/it]#015                                                #015#015 68%|██████▊   | 76/112 [04:03<01:55,  3.20s/it]#015 69%|██████▉   | 77/112 [04:07<01:59,  3.41s/it]#015                                                #015#015 69%|██████▉   | 77/112 [04:07<01:59,  3.41s/it]#015 70%|██████▉   | 78/112 [04:10<01:51,  3.29s/it]#015                                                #015#015 70%|██████▉   | 78/112 [04:10<01:51,  3.29s/it]#015 71%|███████   | 79/112 [04:13<01:47,  3.25s/it]#015                                                #015#015 71%|███████   | 79/112 [04:13<01:47,  3.25s/it]#015 71%|███████▏  | 80/112 [04:16<01:47,  3.36s/it]#015                                                #015#015 71%|███████▏  | 80/112 [04:16<01:47,  3.36s/it]#015 72%|███████▏  | 81/112 [04:20<01:41,  3.29s/it]#015                                                #015#015 72%|███████▏  | 81/112 [04:20<01:41,  3.29s/it]#015 73%|███████▎  | 82/112 [04:22<01:33,  3.12s/it]#015                                                #015#015 73%|███████▎  | 82/112 [04:22<01:33,  3.12s/it]#015 74%|███████▍  | 83/112 [04:25<01:30,  3.12s/it]#015                                                #015#015 74%|███████▍  | 83/112 [04:25<01:30,  3.12s/it]#015 75%|███████▌  | 84/112 [04:28<01:26,  3.08s/it]#015                                                #015#015 75%|███████▌  | 84/112 [04:28<01:26,  3.08s/it]#015 76%|███████▌  | 85/112 [04:32<01:23,  3.09s/it]#015                                                #015#015 76%|███████▌  | 85/112 [04:32<01:23,  3.09s/it]#015 77%|███████▋  | 86/112 [04:35<01:20,  3.10s/it]#015                                                #015#015 77%|███████▋  | 86/112 [04:35<01:20,  3.10s/it]#015 78%|███████▊  | 87/112 [04:38<01:18,  3.15s/it]#015                                                #015#015 78%|███████▊  | 87/112 [04:38<01:18,  3.15s/it]#015 79%|███████▊  | 88/112 [04:42<01:20,  3.35s/it]#015                                                #015#015 79%|███████▊  | 88/112 [04:42<01:20,  3.35s/it]#015 79%|███████▉  | 89/112 [04:45<01:17,  3.37s/it]#015                                                #015#015 79%|███████▉  | 89/112 [04:45<01:17,  3.37s/it]#015 80%|████████  | 90/112 [04:48<01:11,  3.27s/it]#015                                                #015#015 80%|████████  | 90/112 [04:48<01:11,  3.27s/it]#015 81%|████████▏ | 91/112 [04:52<01:10,  3.37s/it]#015                                                #015#015 81%|████████▏ | 91/112 [04:52<01:10,  3.37s/it]#015 82%|████████▏ | 92/112 [04:55<01:06,  3.32s/it]#015                                                #015#015 82%|████████▏ | 92/112 [04:55<01:06,  3.32s/it]#015 83%|████████▎ | 93/112 [04:58<01:04,  3.37s/it]#015                                                #015#015 83%|████████▎ | 93/112 [04:58<01:04,  3.37s/it]#015 84%|████████▍ | 94/112 [05:01<00:57,  3.19s/it]#015                                                #015#015 84%|████████▍ | 94/112 [05:01<00:57,  3.19s/it]#015 85%|████████▍ | 95/112 [05:04<00:53,  3.12s/it]#015                                                #015#015 85%|████████▍ | 95/112 [05:04<00:53,  3.12s/it]#015 86%|████████▌ | 96/112 [05:07<00:49,  3.10s/it]#015                                                #015#015 86%|████████▌ | 96/112 [05:07<00:49,  3.10s/it]#015 87%|████████▋ | 97/112 [05:11<00:47,  3.15s/it]#015                                                #015#015 87%|████████▋ | 97/112 [05:11<00:47,  3.15s/it]#015 88%|████████▊ | 98/112 [05:14<00:46,  3.30s/it]#015                                                #015#015 88%|████████▊ | 98/112 [05:14<00:46,  3.30s/it]#015 88%|████�\u001b[0m\n",
      "\u001b[34m{'loss': 0.773, 'grad_norm': 0.7054450511932373, 'learning_rate': 2.3214285714285715e-05, 'epoch': 1.74}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9721, 'grad_norm': 0.6280956864356995, 'learning_rate': 2.1428571428571428e-05, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5913, 'grad_norm': 0.6814113259315491, 'learning_rate': 1.9642857142857145e-05, 'epoch': 1.78}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6785, 'grad_norm': 0.5761047005653381, 'learning_rate': 1.785714285714286e-05, 'epoch': 1.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7093, 'grad_norm': 0.6765294671058655, 'learning_rate': 1.6071428571428572e-05, 'epoch': 1.81}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5606, 'grad_norm': 0.6224788427352905, 'learning_rate': 1.4285714285714285e-05, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7792, 'grad_norm': 0.6522715091705322, 'learning_rate': 1.25e-05, 'epoch': 1.85}\u001b[0m\n",
      "\u001b[34m{'loss': 0.695, 'grad_norm': 0.8503098487854004, 'learning_rate': 1.0714285714285714e-05, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6381, 'grad_norm': 0.5312905311584473, 'learning_rate': 8.92857142857143e-06, 'epoch': 1.88}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8678, 'grad_norm': 0.8027257919311523, 'learning_rate': 7.142857142857143e-06, 'epoch': 1.9}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6406, 'grad_norm': 0.511856198310852, 'learning_rate': 5.357142857142857e-06, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3885, 'grad_norm': 0.7224913239479065, 'learning_rate': 3.5714285714285714e-06, 'epoch': 1.94}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6575, 'grad_norm': 0.480185329914093, 'learning_rate': 1.7857142857142857e-06, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m{'loss': 0.568, 'grad_norm': 0.812217116355896, 'learning_rate': 0.0, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 362.0728, 'train_samples_per_second': 4.971, 'train_steps_per_second': 0.309, 'train_loss': 1.3016829660960607, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m��███▊ | 99/112 [05:17<00:41,  3.21s/it]#015                                                #015#015 88%|████████▊ | 99/112 [05:17<00:41,  3.21s/it]#015 89%|████████▉ | 100/112 [05:20<00:37,  3.11s/it]#015                                                 #015#015 89%|████████▉ | 100/112 [05:20<00:37,  3.11s/it]#015 90%|█████████ | 101/112 [05:23<00:33,  3.01s/it]#015                                                 #015#015 90%|█████████ | 101/112 [05:23<00:33,  3.01s/it]#015 91%|█████████ | 102/112 [05:26<00:31,  3.11s/it]#015                                                 #015#015 91%|█████████ | 102/112 [05:26<00:31,  3.11s/it]#015 92%|█████████▏| 103/112 [05:29<00:28,  3.17s/it]#015                                                 #015#015 92%|█████████▏| 103/112 [05:29<00:28,  3.17s/it]#015 93%|█████████▎| 104/112 [05:33<00:25,  3.14s/it]#015                                                 #015#015 93%|█████████▎| 104/112 [05:33<00:25,  3.14s/it]#015 94%|█████████▍| 105/112 [05:36<00:22,  3.24s/it]#015                                                 #015#015 94%|█████████▍| 105/112 [05:36<00:22,  3.24s/it]#015 95%|█████████▍| 106/112 [05:39<00:18,  3.13s/it]#015                                                 #015#015 95%|█████████▍| 106/112 [05:39<00:18,  3.13s/it]#015 96%|█████████▌| 107/112 [05:43<00:16,  3.28s/it]#015                                                 #015#015 96%|█████████▌| 107/112 [05:43<00:16,  3.28s/it]#015 96%|█████████▋| 108/112 [05:46<00:13,  3.35s/it]#015                                                 #015#015 96%|█████████▋| 108/112 [05:46<00:13,  3.35s/it]#015 97%|█████████▋| 109/112 [05:50<00:10,  3.59s/it]#015                                                 #015#015 97%|█████████▋| 109/112 [05:50<00:10,  3.59s/it]#015 98%|█████████▊| 110/112 [05:53<00:06,  3.46s/it]#015                                                 #015#015 98%|█████████▊| 110/112 [05:53<00:06,  3.46s/it]#015 99%|█████████▉| 111/112 [05:57<00:03,  3.45s/it]#015                                                 #015#015 99%|█████████▉| 111/112 [05:57<00:03,  3.45s/it]#015100%|██████████| 112/112 [06:00<00:00,  3.25s/it]#015                                                 #015#015100%|██████████| 112/112 [06:00<00:00,  3.25s/it]#015                                                 #015#015100%|██████████| 112/112 [06:00<00:00,  3.25s/it]2024-12-18 09:55:15,312 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/results\u001b[0m\n",
      "\u001b[34m2024-12-18 09:55:15,312 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/results\u001b[0m\n",
      "\u001b[34m2024-12-18 09:55:15,313 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/results\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:485 [3] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:485 [3] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:485 [3] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:213 [3] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 112/112 [06:01<00:00,  3.22s/it]\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:486 [1] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:486 [1] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:486 [1] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:214 [1] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:133:485 [3] NCCL INFO comm 0x55582f8cfc20 rank 3 nranks 4 cudaDev 3 busId 1e0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:131:486 [1] NCCL INFO comm 0x5614653e7080 rank 1 nranks 4 cudaDev 1 busId 1c0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:487 [2] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:487 [2] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:487 [2] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:215 [2] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:132:487 [2] NCCL INFO comm 0x5651e1f48220 rank 2 nranks 4 cudaDev 2 busId 1d0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]#015Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.09s/it]#015Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.00s/it]#015Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.73s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.61s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.08s/it]\u001b[0m\n",
      "\u001b[34m2024-12-18 09:56:47,200 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://amazon-sagemaker-691148928602-us-east-1-36d3a3ecb842/dzd_6u9itn3p91gb1j/crerj7yeukbc4n/dev/train-Falcon3-7B-Instruct-2024-12-18-09-33-11-159/results\u001b[0m\n",
      "\u001b[34m[rank0]:[W1218 09:56:47.909671393 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:493 [0] NCCL INFO misc/socket.cc:47 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:493 [0] NCCL INFO misc/socket.cc:58 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:493 [0] NCCL INFO misc/socket.cc:781 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:216 [0] NCCL INFO misc/socket.cc:832 -> 3\u001b[0m\n",
      "\u001b[34mip-10-38-214-11:130:493 [0] NCCL INFO comm 0x564ba461efe0 rank 0 nranks 4 cudaDev 0 busId 1b0 - Abort COMPLETE\u001b[0m\n",
      "\n",
      "2024-12-18 09:57:49 Uploading - Uploading generated training model\n",
      "2024-12-18 09:58:58 Completed - Resource retained for reuse\n",
      "Training seconds: 1441\n",
      "Billable seconds: 1441\n"
     ]
    }
   ],
   "source": [
    "train_fn(\n",
    "    model_id,\n",
    "    train_ds=train_dataset,\n",
    "    test_ds=test_dataset,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    num_train_epochs=2,\n",
    "    merge_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Fine-Tuned model\n",
    "\n",
    "Note: Run `train_fn` with `merge_weights=True` for merging the trained adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:08.515277Z",
     "start_time": "2023-11-20T18:41:08.503555Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T13:45:11.757861Z",
     "start_time": "2023-09-03T13:45:11.747993Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"tiiuae/Falcon3-7B-Instruct\"\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    import boto3\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    \n",
    "    search_response = sagemaker_client.search(\n",
    "        Resource='TrainingJob',\n",
    "        SearchExpression={\n",
    "            'Filters': [\n",
    "                {\n",
    "                    'Name': 'TrainingJobName',\n",
    "                    'Operator': 'Contains',\n",
    "                    'Value': job_name_prefix\n",
    "                },\n",
    "                {\n",
    "                    'Name': 'TrainingJobStatus',\n",
    "                    'Operator': 'Equals',\n",
    "                    'Value': \"Completed\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "        MaxResults=1)\n",
    "    \n",
    "    return search_response['Results'][0]['TrainingJob']['TrainingJobName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:10.492877Z",
     "start_time": "2023-11-20T18:41:10.488495Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.4xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-lmi\",\n",
    "    region=sagemaker_session.boto_session.region_name,\n",
    "    version=\"latest\"\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:12.433399Z",
     "start_time": "2023-11-20T18:41:11.963091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=f\"s3://{bucket_name}/{job_name}/{job_name}/output/model.tar.gz\",\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "        'OPTION_TRUST_REMOTE_CODE': 'true',\n",
    "        'OPTION_ROLLING_BATCH': \"vllm\",\n",
    "        'OPTION_DTYPE': 'bf16',\n",
    "        'OPTION_TENSOR_PARALLEL_DEGREE': 'max',\n",
    "        'OPTION_MAX_ROLLING_BATCH_SIZE': '1',\n",
    "        'OPTION_MODEL_LOADING_TIMEOUT': '3600',\n",
    "        'OPTION_MAX_MODEL_LEN': '4096'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"tiiuae/Falcon3-7B-Instruct\"\n",
    "\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-djl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:45:49.265298Z",
     "start_time": "2023-11-20T18:41:14.621743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    model_data_download_timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"tiiuae/Falcon3-7B-Instruct\"\n",
    "\n",
    "endpoint_name = f\"{model_id.split('/')[-1].replace('.', '-')}-djl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = f\"\"\"<|user|>\\n{{question}}<|assistant|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = base_prompt.format(question=\"What statue is in front of the Notre Dame building?\")\n",
    "\n",
    "predictor.predict({\n",
    "\t\"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 300,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"stop\": ['<|im_end|>']\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:48:55.153276Z",
     "start_time": "2023-11-20T18:48:54.165351Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
