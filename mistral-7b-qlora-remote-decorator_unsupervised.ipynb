{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fine-tune Mistral-7B with QLoRA and SageMaker remote decorator\n",
    "\n",
    "## Unsupervised fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this demo notebook, we demonstrate how to fine-tune the Mistral-7B model using QLoRA, Hugging Face PEFT, and bitsandbytes.\n",
    "\n",
    "We are using SageMaker remote decorator for runinng the fine-tuning job on Amazon SageMaker Training job\n",
    "---\n",
    "SageMaker Studio Kernel: PyTorch 2.0.0 Python 3.10\n",
    "\n",
    "JupyterLab Instance Type: ml.t3.medium\n",
    "\n",
    "Fine-Tuning:\n",
    "* Instance Type: ml.g5.12xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libriaries, including the Hugging Face libraries, and restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:07:37.160628Z",
     "start_time": "2024-01-26T09:07:24.214358Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:08:34.593905Z",
     "start_time": "2024-01-26T09:07:40.813986Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-ai 2.6.0 requires faiss-cpu, which is not installed.\n",
      "jupyter-ai 2.6.0 requires langchain==0.0.318, but you have langchain 0.1.5 which is incompatible.\n",
      "jupyter-ai-magics 2.6.0 requires langchain==0.0.318, but you have langchain 0.1.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U datasets==2.16.1\n",
    "%pip install -q -U langchain==0.1.5\n",
    "%pip install -q -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup Configuration file path\n",
    "\n",
    "We are setting the directory in which the config.yaml file resides so that remote decorator can make use of the settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:10:25.268548Z",
     "start_time": "2024-01-26T09:10:25.266384Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set path to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and upload the dataset\n",
    "\n",
    "Read train dataset in a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:10:30.198991Z",
     "start_time": "2024-01-26T09:10:26.881694Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader([\n",
    "    \"https://aws.amazon.com/bedrock/\",\n",
    "    \"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\",\n",
    "    \"https://aws.amazon.com/blogs/aws/preview-enable-foundation-models-to-complete-tasks-with-agents-for-amazon-bedrock/\",\n",
    "    \"https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html\",\n",
    "    \"https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html\",\n",
    "\n",
    "])\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:10:38.812254Z",
     "start_time": "2024-01-26T09:10:36.505800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def strip_spaces(doc):\n",
    "    return {\"text\": doc.page_content.replace(\"  \", \"\")}\n",
    "\n",
    "stripped_data = list(map(strip_spaces, data))\n",
    "\n",
    "train_dataset = Dataset.from_list(stripped_data)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:10:51.943040Z",
     "start_time": "2024-01-26T09:10:41.527153Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b95b6d2387404fbbb3ca2cba0c93a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df34f5d0afcb442882ec45325231af81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3009f17ff0fd42e4bf2fbe04a3896e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e11c9679b1e44e3b30962b5e812e208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating chunks and tokenizing the inputs for making it usable by the LLM. For additional details, please refer to the blog [Leveraging qLoRA for Fine-Tuning of Task-Fine-Tuned Models Without Catastrophic Forgetting: A Case Study with LLaMA2(-chat)](https://medium.com/towards-data-science/leveraging-qlora-for-fine-tuning-of-task-fine-tuned-models-without-catastrophic-forgetting-d9bcd594cff4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:11:28.748430Z",
     "start_time": "2024-01-26T09:11:28.742863Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}\n",
    "\n",
    "def chunk(sample, chunk_length=2048):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To train our model, we need to convert our inputs (text) to token IDs. This is done by a Hugging Face Transformers Tokenizer. In addition to QLoRA, we will use bitsanbytes 4-bit precision to quantize out frozen LLM to 4-bit and attach LoRA adapters on it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:10:38.829988Z",
     "start_time": "2024-01-26T09:10:38.809336Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility method for finding the target modules and update the necessary matrices. Visit [this](https://github.com/artidoro/qlora/blob/main/qlora.py) link for additional info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T09:11:31.665117Z",
     "start_time": "2024-01-26T09:11:31.116541Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(hf_model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in hf_model.named_modules():\n",
    "        if isinstance(module, bnb.nn.Linear4bit):\n",
    "            names = name.split(\".\")\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n",
    "        lora_module_names.remove(\"lm_head\")\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:25:06.721135Z",
     "start_time": "2023-11-20T18:25:04.369468Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Fetched defaults config from location: /home/sagemaker-user/sagemaker-new/amazon-sagemaker-remote-decorator-generative-ai\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.ImageUri\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.InstanceType\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sagemaker.remote_function import remote\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import transformers\n",
    "\n",
    "# Start training\n",
    "@remote(volume_size=100, job_name_prefix=f\"train-{model_id.split('/')[-1].replace('.', '-')}-merge\")\n",
    "def train_fn(\n",
    "        model_name,\n",
    "        train_ds,\n",
    "        test_ds=None,\n",
    "        lora_r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=2e-4,\n",
    "        num_train_epochs=1,\n",
    "        chunk_size=2048,\n",
    "        merge_weights=False,\n",
    "        token=None\n",
    "):\n",
    "    if token is not None:\n",
    "        login(token=token)\n",
    "\n",
    "    # tokenize and chunk dataset\n",
    "    lm_train_dataset = train_ds.map(\n",
    "        lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(train_ds.features)\n",
    "    ).map(\n",
    "        partial(chunk, chunk_length=chunk_size),\n",
    "        batched=True,\n",
    "    )\n",
    "\n",
    "    if test_ds is not None:\n",
    "        lm_test_dataset = test_ds.map(\n",
    "            lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(test_ds.features)\n",
    "        ).map(\n",
    "            partial(chunk, chunk_length=chunk_size),\n",
    "            batched=True,\n",
    "        )\n",
    "\n",
    "        print(f\"Total number of test samples: {len(lm_test_dataset)}\")\n",
    "    else:\n",
    "        lm_test_dataset = None\n",
    "\n",
    "    # Print total number of samples\n",
    "    print(f\"Total number of train samples: {len(lm_dataset)}\")\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\")\n",
    "\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
    "\n",
    "    # get lora target modules\n",
    "    modules = find_all_linear_names(model)\n",
    "    print(f\"Found {len(modules)} modules to quantize: {modules}\")\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "    print_trainable_parameters(model)\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=lm_train_dataset,\n",
    "        eval_dataset=lm_test_dataset if lm_test_dataset is not None else None,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "            logging_steps=2,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            bf16=True,\n",
    "            save_strategy=\"no\",\n",
    "            output_dir=\"outputs\"\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    if merge_weights:\n",
    "        output_dir = \"/tmp/model\"\n",
    "\n",
    "        # merge adapter weights with base model and save\n",
    "        # save int 4 model\n",
    "        trainer.model.save_pretrained(output_dir, safe_serialization=False)\n",
    "        # clear memory\n",
    "        del model\n",
    "        del trainer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # load PEFT model in fp16\n",
    "        model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            output_dir,\n",
    "            low_cpu_mem_usage=True,\n",
    "            torch_dtype=torch.float16,\n",
    "        )\n",
    "        # Merge LoRA and base model and save\n",
    "        model = model.merge_and_unload()\n",
    "        model.save_pretrained(\n",
    "            \"/opt/ml/model\", safe_serialization=True, max_shard_size=\"2GB\"\n",
    "        )\n",
    "    else:\n",
    "        model.save_pretrained(\"/opt/ml/model\", safe_serialization=True)\n",
    "\n",
    "    tmp_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tmp_tokenizer.save_pretrained(\"/opt/ml/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T21:04:05.465078Z",
     "start_time": "2023-11-14T20:43:26.848983Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 00:55:41,107 sagemaker.remote_function INFO     Serializing function code to s3://sagemaker-eu-west-1-691148928602/train-Mistral-7B-Instruct-v0-1-merge-2024-02-05-00-55-41-107/function\n",
      "2024-02-05 00:55:41,283 sagemaker.remote_function INFO     Serializing function arguments to s3://sagemaker-eu-west-1-691148928602/train-Mistral-7B-Instruct-v0-1-merge-2024-02-05-00-55-41-107/arguments\n",
      "2024-02-05 00:55:41,523 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpy4qe6wrs/temp_workspace/sagemaker_remote_function_workspace/requirements.txt'\n",
      "2024-02-05 00:55:41,525 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmpy4qe6wrs/workspace.zip'\n",
      "2024-02-05 00:55:41,572 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-eu-west-1-691148928602/train-Mistral-7B-Instruct-v0-1-merge-2024-02-05-00-55-41-107/sm_rf_user_ws/workspace.zip'\n",
      "2024-02-05 00:55:41,574 sagemaker.remote_function INFO     Creating job: train-Mistral-7B-Instruct-v0-1-merge-2024-02-05-00-55-41-107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-05 00:55:41 Starting - Starting the training job...\n",
      "2024-02-05 00:56:06 Starting - Preparing the instances for training.........\n",
      "2024-02-05 00:57:21 Downloading - Downloading input data...\n",
      "2024-02-05 00:57:56 Downloading - Downloading the training image...............\n",
      "2024-02-05 01:00:37 Training - Training image download completed. Training in progress........\u001b[34mINFO: CONDA_PKGS_DIRS is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/conda/pkgs'\u001b[0m\n",
      "\u001b[34mINFO: PIP_CACHE_DIR is set to '/opt/ml/sagemaker/warmpoolcache/sm_remotefunction_user_dependencies_cache/pip'\u001b[0m\n",
      "\u001b[34mINFO: Bootstraping runtime environment.\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,313 sagemaker.remote_function INFO     Successfully unpacked workspace archive at '/'.\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,313 sagemaker.remote_function INFO     '/sagemaker_remote_function_workspace/pre_exec.sh' does not exist. Assuming no pre-execution commands to run\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,313 sagemaker.remote_function INFO     Running command: '/opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U' in the dir: '/' \u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,757 sagemaker.remote_function INFO     Collecting transformers==4.37.2 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,779 sagemaker.remote_function INFO       Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,793 sagemaker.remote_function INFO          ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.4/129.4 kB 10.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,814 sagemaker.remote_function INFO     Collecting peft==0.7.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,819 sagemaker.remote_function INFO       Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,844 sagemaker.remote_function INFO     Collecting accelerate==0.26.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,848 sagemaker.remote_function INFO       Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,869 sagemaker.remote_function INFO     Collecting bitsandbytes==0.42.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,872 sagemaker.remote_function INFO       Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,982 sagemaker.remote_function INFO     Collecting safetensors>=0.3.1 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:44,986 sagemaker.remote_function INFO       Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,061 sagemaker.remote_function INFO     Collecting sagemaker==2.206.0 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,065 sagemaker.remote_function INFO       Downloading sagemaker-2.206.0-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,068 sagemaker.remote_function INFO     Requirement already satisfied: tokenizers>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from -r /sagemaker_remote_function_workspace/requirements.txt (line 7)) (0.13.3)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,247 sagemaker.remote_function INFO     Collecting tokenizers>=0.13.3 (from -r /sagemaker_remote_function_workspace/requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,251 sagemaker.remote_function INFO       Downloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,310 sagemaker.remote_function INFO     Collecting py7zr (from -r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,314 sagemaker.remote_function INFO       Downloading py7zr-0.20.8-py3-none-any.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,741 sagemaker.remote_function INFO     Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.12.2)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,742 sagemaker.remote_function INFO     Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,742 sagemaker.remote_function INFO     Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,743 sagemaker.remote_function INFO     Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,744 sagemaker.remote_function INFO     Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (6.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,744 sagemaker.remote_function INFO     Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,744 sagemaker.remote_function INFO     Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,751 sagemaker.remote_function INFO     Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,771 sagemaker.remote_function INFO     Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,772 sagemaker.remote_function INFO     Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,821 sagemaker.remote_function INFO     Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 4)) (1.11.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,870 sagemaker.remote_function INFO     Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (23.1.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,871 sagemaker.remote_function INFO     Requirement already satisfied: boto3<2.0,>=1.33.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.34.34)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,871 sagemaker.remote_function INFO     Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (2.2.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,872 sagemaker.remote_function INFO     Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.2.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,873 sagemaker.remote_function INFO     Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (3.20.2)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,873 sagemaker.remote_function INFO     Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.0.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,874 sagemaker.remote_function INFO     Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (6.8.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,874 sagemaker.remote_function INFO     Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (2.0.3)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,874 sagemaker.remote_function INFO     Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.3.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,875 sagemaker.remote_function INFO     Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.7.5)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,876 sagemaker.remote_function INFO     Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (4.18.3)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,876 sagemaker.remote_function INFO     Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (3.8.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,876 sagemaker.remote_function INFO     Requirement already satisfied: tblib<3,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.7.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,877 sagemaker.remote_function INFO     Requirement already satisfied: urllib3<1.27 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.26.15)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,910 sagemaker.remote_function INFO     Collecting docker (from sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:45,912 sagemaker.remote_function INFO       Downloading docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,001 sagemaker.remote_function INFO     Collecting texttable (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,004 sagemaker.remote_function INFO       Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,111 sagemaker.remote_function INFO     Collecting pycryptodomex>=3.16.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,114 sagemaker.remote_function INFO       Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,227 sagemaker.remote_function INFO     Collecting pyzstd>=0.15.9 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,230 sagemaker.remote_function INFO       Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,321 sagemaker.remote_function INFO     Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,324 sagemaker.remote_function INFO       Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,375 sagemaker.remote_function INFO     Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,379 sagemaker.remote_function INFO       Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,395 sagemaker.remote_function INFO     Collecting multivolumefile>=0.2.3 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,397 sagemaker.remote_function INFO       Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,451 sagemaker.remote_function INFO     Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,455 sagemaker.remote_function INFO       Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,490 sagemaker.remote_function INFO     Collecting brotli>=1.1.0 (from py7zr->-r /sagemaker_remote_function_workspace/requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,493 sagemaker.remote_function INFO       Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,520 sagemaker.remote_function INFO     Requirement already satisfied: botocore<1.35.0,>=1.34.34 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.34.34)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,520 sagemaker.remote_function INFO     Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.0.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,521 sagemaker.remote_function INFO     Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.10.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,604 sagemaker.remote_function INFO     Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2023.6.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,605 sagemaker.remote_function INFO     Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (4.7.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,625 sagemaker.remote_function INFO     Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (3.16.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,715 sagemaker.remote_function INFO     Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (1.12)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,716 sagemaker.remote_function INFO     Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,716 sagemaker.remote_function INFO     Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,762 sagemaker.remote_function INFO     Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,763 sagemaker.remote_function INFO     Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,763 sagemaker.remote_function INFO     Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.37.2->-r /sagemaker_remote_function_workspace/requirements.txt (line 1)) (2024.2.2)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,780 sagemaker.remote_function INFO     Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,800 sagemaker.remote_function INFO     Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (2023.6.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,801 sagemaker.remote_function INFO     Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.29.1)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,802 sagemaker.remote_function INFO     Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.8.10)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,921 sagemaker.remote_function INFO     Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (2.8.2)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,922 sagemaker.remote_function INFO     Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (2023.3)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,923 sagemaker.remote_function INFO     Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (2023.3)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,931 sagemaker.remote_function INFO     Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (1.7.6.6)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,932 sagemaker.remote_function INFO     Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.3.6)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,933 sagemaker.remote_function INFO     Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.3.2)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,933 sagemaker.remote_function INFO     Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (0.70.14)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:46,964 sagemaker.remote_function INFO     Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker==2.206.0->-r /sagemaker_remote_function_workspace/requirements.txt (line 6)) (21.6.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,176 sagemaker.remote_function INFO     Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.7.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,205 sagemaker.remote_function INFO     Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.7.1->-r /sagemaker_remote_function_workspace/requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,240 sagemaker.remote_function INFO     Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,297 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 156.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,301 sagemaker.remote_function INFO     Downloading peft-0.7.1-py3-none-any.whl (168 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,305 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.3/168.3 kB 71.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,308 sagemaker.remote_function INFO     Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,314 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 270.9/270.9 kB 86.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:47,318 sagemaker.remote_function INFO     Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,104 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 50.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,115 sagemaker.remote_function INFO     Downloading sagemaker-2.206.0-py3-none-any.whl (1.4 MB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,127 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 147.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,133 sagemaker.remote_function INFO     Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,144 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 143.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,151 sagemaker.remote_function INFO     Downloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,177 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 151.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,180 sagemaker.remote_function INFO     Downloading py7zr-0.20.8-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,184 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 kB 31.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,187 sagemaker.remote_function INFO     Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,208 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 166.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,212 sagemaker.remote_function INFO     Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,216 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.1/93.1 kB 43.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,220 sagemaker.remote_function INFO     Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,223 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.7/49.7 kB 25.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,226 sagemaker.remote_function INFO     Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,242 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 157.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,247 sagemaker.remote_function INFO     Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,252 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.9/138.9 kB 43.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,256 sagemaker.remote_function INFO     Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,261 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 412.3/412.3 kB 116.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,265 sagemaker.remote_function INFO     Downloading docker-7.0.0-py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,269 sagemaker.remote_function INFO        ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.6/147.6 kB 65.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:48,272 sagemaker.remote_function INFO     Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:50,785 sagemaker.remote_function INFO     Installing collected packages: texttable, brotli, safetensors, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr, docker, bitsandbytes, tokenizers, accelerate, transformers, sagemaker, peft\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,826 sagemaker.remote_function INFO       Attempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,828 sagemaker.remote_function INFO         Found existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,832 sagemaker.remote_function INFO         Uninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,849 sagemaker.remote_function INFO           Successfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,923 sagemaker.remote_function INFO       Attempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,924 sagemaker.remote_function INFO         Found existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,932 sagemaker.remote_function INFO         Uninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:52,955 sagemaker.remote_function INFO           Successfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:53,086 sagemaker.remote_function INFO       Attempting uninstall: transformers\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:53,089 sagemaker.remote_function INFO         Found existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:53,219 sagemaker.remote_function INFO         Uninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:53,598 sagemaker.remote_function INFO           Successfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:57,538 sagemaker.remote_function INFO       Attempting uninstall: sagemaker\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:57,540 sagemaker.remote_function INFO         Found existing installation: sagemaker 2.172.0\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:57,575 sagemaker.remote_function INFO         Uninstalling sagemaker-2.172.0:\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:57,683 sagemaker.remote_function INFO           Successfully uninstalled sagemaker-2.172.0\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:58,384 sagemaker.remote_function INFO     Successfully installed accelerate-0.26.1 bitsandbytes-0.42.0 brotli-1.1.0 docker-7.0.0 inflate64-1.0.0 multivolumefile-0.2.3 peft-0.7.1 py7zr-0.20.8 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.15.9 safetensors-0.4.2 sagemaker-2.206.0 texttable-1.7.0 tokenizers-0.15.1 transformers-4.37.2\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:58,750 sagemaker.remote_function WARNING  WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:58,750 sagemaker.remote_function WARNING  \u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:58,750 sagemaker.remote_function WARNING  [notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:58,750 sagemaker.remote_function WARNING  [notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:58,750 sagemaker.remote_function INFO     Command /opt/conda/bin/python -m pip install -r /sagemaker_remote_function_workspace/requirements.txt -U ran successfully\u001b[0m\n",
      "\u001b[34mINFO: Changing workspace to sagemaker_remote_function_workspace.\u001b[0m\n",
      "\u001b[34mINFO: No conda env provided. Invoking remote function\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34m2024-02-05 01:01:59,906 sagemaker.remote_function INFO     Deserializing function code from s3://sagemaker-eu-west-1-691148928602/train-Mistral-7B-Instruct-v0-1-merge-2024-02-05-00-55-41-107/function\u001b[0m\n",
      "\u001b[34m2024-02-05 01:02:03,331 sagemaker.remote_function INFO     Deserializing function arguments from s3://sagemaker-eu-west-1-691148928602/train-Mistral-7B-Instruct-v0-1-merge-2024-02-05-00-55-41-107/arguments\u001b[0m\n",
      "\u001b[34mINFO:datasets:PyTorch version 2.0.0 available.\u001b[0m\n",
      "\u001b[34m2024-02-05 01:02:03,596 sagemaker.remote_function INFO     Resolving pipeline variables\u001b[0m\n",
      "\u001b[34m2024-02-05 01:02:03,596 sagemaker.remote_function INFO     Invoking the function\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/5 [00:00<?, ? examples/s]#015Map: 100%|██████████| 5/5 [00:00<00:00, 207.62 examples/s]\u001b[0m\n",
      "\u001b[34m#015Map:   0%|          | 0/5 [00:00<?, ? examples/s]#015Map: 100%|██████████| 5/5 [00:00<00:00, 434.87 examples/s]\u001b[0m\n",
      "\u001b[34mTotal number of train samples: 4\u001b[0m\n",
      "\u001b[34m#015config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]#015config.json: 100%|██████████| 571/571 [00:00<00:00, 5.84MB/s]\u001b[0m\n",
      "\u001b[34m#015model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]#015model.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 187MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   0%|          | 21.0M/9.94G [00:00<00:49, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   1%|          | 52.4M/9.94G [00:00<00:38, 254MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   1%|          | 94.4M/9.94G [00:00<00:31, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   1%|▏         | 136M/9.94G [00:00<00:30, 325MB/s] #033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   2%|▏         | 178M/9.94G [00:00<00:28, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   2%|▏         | 220M/9.94G [00:00<00:27, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   3%|▎         | 262M/9.94G [00:00<00:27, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   3%|▎         | 304M/9.94G [00:00<00:26, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   3%|▎         | 346M/9.94G [00:01<00:28, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   4%|▍         | 388M/9.94G [00:01<00:27, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   4%|▍         | 430M/9.94G [00:01<00:27, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   5%|▍         | 472M/9.94G [00:01<00:27, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   5%|▌         | 514M/9.94G [00:01<00:29, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   6%|▌         | 556M/9.94G [00:01<00:29, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   6%|▌         | 598M/9.94G [00:01<00:27, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   6%|▋         | 640M/9.94G [00:01<00:27, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   7%|▋         | 682M/9.94G [00:02<00:28, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   7%|▋         | 724M/9.94G [00:02<00:26, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   8%|▊         | 765M/9.94G [00:02<00:25, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   8%|▊         | 818M/9.94G [00:02<00:24, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   9%|▊         | 860M/9.94G [00:02<00:23, 379MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   9%|▉         | 902M/9.94G [00:02<00:23, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:   9%|▉         | 944M/9.94G [00:02<00:24, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  10%|▉         | 986M/9.94G [00:02<00:24, 370MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  10%|█         | 1.03G/9.94G [00:02<00:23, 379MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  11%|█         | 1.07G/9.94G [00:03<00:23, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  11%|█         | 1.11G/9.94G [00:03<00:23, 383MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  12%|█▏        | 1.15G/9.94G [00:03<00:23, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  12%|█▏        | 1.20G/9.94G [00:03<00:22, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  12%|█▏        | 1.24G/9.94G [00:03<00:23, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  13%|█▎        | 1.28G/9.94G [00:03<00:25, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  13%|█▎        | 1.32G/9.94G [00:03<00:24, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  14%|█▎        | 1.36G/9.94G [00:03<00:23, 363MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  14%|█▍        | 1.41G/9.94G [00:03<00:23, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  15%|█▍        | 1.45G/9.94G [00:04<00:22, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  15%|█▍        | 1.49G/9.94G [00:04<00:23, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  15%|█▌        | 1.53G/9.94G [00:04<00:22, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  16%|█▌        | 1.57G/9.94G [00:04<00:22, 374MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  16%|█▌        | 1.61G/9.94G [00:04<00:21, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  17%|█▋        | 1.66G/9.94G [00:04<00:21, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  17%|█▋        | 1.70G/9.94G [00:04<00:22, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  18%|█▊        | 1.74G/9.94G [00:04<00:23, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  18%|█▊        | 1.78G/9.94G [00:05<00:29, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  18%|█▊        | 1.81G/9.94G [00:05<00:31, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  19%|█▊        | 1.86G/9.94G [00:05<00:31, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  19%|█▉        | 1.90G/9.94G [00:05<00:28, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  20%|█▉        | 1.94G/9.94G [00:05<00:26, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  20%|█▉        | 1.98G/9.94G [00:05<00:25, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  20%|██        | 2.02G/9.94G [00:05<00:24, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  21%|██        | 2.07G/9.94G [00:06<00:24, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  21%|██        | 2.11G/9.94G [00:06<00:23, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  22%|██▏       | 2.15G/9.94G [00:06<00:22, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  22%|██▏       | 2.19G/9.94G [00:06<00:21, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  22%|██▏       | 2.23G/9.94G [00:06<00:22, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  23%|██▎       | 2.28G/9.94G [00:06<00:21, 360MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  23%|██▎       | 2.32G/9.94G [00:06<00:21, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  24%|██▎       | 2.36G/9.94G [00:06<00:20, 362MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  24%|██▍       | 2.40G/9.94G [00:06<00:20, 374MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  25%|██▍       | 2.44G/9.94G [00:07<00:20, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  25%|██▍       | 2.49G/9.94G [00:07<00:20, 369MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  25%|██▌       | 2.53G/9.94G [00:07<00:20, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  26%|██▌       | 2.57G/9.94G [00:07<00:20, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  26%|██▋       | 2.61G/9.94G [00:07<00:19, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  27%|██▋       | 2.65G/9.94G [00:07<00:20, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  27%|██▋       | 2.69G/9.94G [00:07<00:20, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  28%|██▊       | 2.74G/9.94G [00:07<00:20, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  28%|██▊       | 2.78G/9.94G [00:08<00:21, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  28%|██▊       | 2.82G/9.94G [00:08<00:20, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  29%|██▉       | 2.86G/9.94G [00:08<00:19, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  29%|██▉       | 2.90G/9.94G [00:08<00:19, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  30%|██▉       | 2.95G/9.94G [00:08<00:20, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  30%|███       | 2.99G/9.94G [00:08<00:19, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  30%|███       | 3.03G/9.94G [00:08<00:19, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  31%|███       | 3.07G/9.94G [00:08<00:19, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  31%|███▏      | 3.11G/9.94G [00:08<00:19, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  32%|███▏      | 3.16G/9.94G [00:09<00:22, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  32%|███▏      | 3.20G/9.94G [00:09<00:21, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  33%|███▎      | 3.24G/9.94G [00:09<00:19, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  33%|███▎      | 3.28G/9.94G [00:09<00:19, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  33%|███▎      | 3.32G/9.94G [00:09<00:19, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  34%|███▍      | 3.37G/9.94G [00:09<00:18, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  34%|███▍      | 3.41G/9.94G [00:09<00:18, 362MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  35%|███▍      | 3.45G/9.94G [00:09<00:17, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  35%|███▌      | 3.49G/9.94G [00:10<00:18, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  36%|███▌      | 3.53G/9.94G [00:10<00:17, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  36%|███▌      | 3.58G/9.94G [00:10<00:19, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  36%|███▋      | 3.62G/9.94G [00:10<00:18, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  37%|███▋      | 3.66G/9.94G [00:10<00:20, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  37%|███▋      | 3.70G/9.94G [00:10<00:19, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  38%|███▊      | 3.74G/9.94G [00:10<00:19, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  38%|███▊      | 3.79G/9.94G [00:11<00:19, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  38%|███▊      | 3.83G/9.94G [00:11<00:19, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  39%|███▉      | 3.86G/9.94G [00:11<00:19, 306MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  39%|███▉      | 3.89G/9.94G [00:11<00:22, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  39%|███▉      | 3.92G/9.94G [00:11<00:24, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  40%|███▉      | 3.95G/9.94G [00:11<00:24, 242MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  40%|████      | 4.00G/9.94G [00:11<00:21, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  41%|████      | 4.04G/9.94G [00:11<00:20, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  41%|████      | 4.08G/9.94G [00:12<00:18, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  41%|████▏     | 4.12G/9.94G [00:12<00:17, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  42%|████▏     | 4.16G/9.94G [00:12<00:17, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  42%|████▏     | 4.20G/9.94G [00:12<00:17, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  43%|████▎     | 4.25G/9.94G [00:12<00:16, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  43%|████▎     | 4.29G/9.94G [00:12<00:18, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  44%|████▎     | 4.33G/9.94G [00:12<00:17, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  44%|████▍     | 4.37G/9.94G [00:12<00:16, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  44%|████▍     | 4.41G/9.94G [00:13<00:16, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  45%|████▍     | 4.46G/9.94G [00:13<00:16, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  45%|████▌     | 4.50G/9.94G [00:13<00:16, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  46%|████▌     | 4.54G/9.94G [00:13<00:15, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  46%|████▌     | 4.58G/9.94G [00:13<00:16, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  47%|████▋     | 4.62G/9.94G [00:13<00:16, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  47%|████▋     | 4.67G/9.94G [00:13<00:15, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  47%|████▋     | 4.71G/9.94G [00:13<00:15, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  48%|████▊     | 4.75G/9.94G [00:14<00:14, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  48%|████▊     | 4.79G/9.94G [00:14<00:14, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  49%|████▊     | 4.83G/9.94G [00:14<00:15, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  49%|████▉     | 4.88G/9.94G [00:14<00:14, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  49%|████▉     | 4.92G/9.94G [00:14<00:15, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  50%|████▉     | 4.96G/9.94G [00:14<00:14, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  50%|█████     | 5.00G/9.94G [00:14<00:21, 233MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  51%|█████     | 5.03G/9.94G [00:15<00:19, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  51%|█████     | 5.09G/9.94G [00:15<00:17, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  52%|█████▏    | 5.13G/9.94G [00:15<00:16, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  52%|█████▏    | 5.17G/9.94G [00:15<00:15, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  52%|█████▏    | 5.21G/9.94G [00:15<00:15, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  53%|█████▎    | 5.25G/9.94G [00:15<00:15, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  53%|█████▎    | 5.30G/9.94G [00:15<00:15, 306MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  54%|█████▎    | 5.34G/9.94G [00:15<00:14, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  54%|█████▍    | 5.38G/9.94G [00:16<00:13, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  55%|█████▍    | 5.42G/9.94G [00:16<00:12, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  55%|█████▍    | 5.46G/9.94G [00:16<00:14, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  55%|█████▌    | 5.51G/9.94G [00:16<00:14, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  56%|█████▌    | 5.55G/9.94G [00:16<00:13, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  56%|█████▌    | 5.59G/9.94G [00:16<00:14, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  57%|█████▋    | 5.62G/9.94G [00:16<00:14, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  57%|█████▋    | 5.65G/9.94G [00:17<00:16, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  57%|█████▋    | 5.68G/9.94G [00:17<00:16, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  57%|█████▋    | 5.71G/9.94G [00:17<00:18, 226MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  58%|█████▊    | 5.75G/9.94G [00:17<00:19, 221MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  58%|█████▊    | 5.78G/9.94G [00:17<00:18, 219MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  58%|█████▊    | 5.81G/9.94G [00:17<00:19, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  59%|█████▊    | 5.84G/9.94G [00:17<00:18, 226MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  59%|█████▉    | 5.88G/9.94G [00:18<00:16, 253MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  59%|█████▉    | 5.91G/9.94G [00:18<00:15, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  60%|█████▉    | 5.95G/9.94G [00:18<00:15, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  60%|██████    | 5.98G/9.94G [00:18<00:14, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  61%|██████    | 6.02G/9.94G [00:18<00:13, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  61%|██████    | 6.05G/9.94G [00:18<00:13, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  61%|██████    | 6.08G/9.94G [00:18<00:14, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  61%|██████▏   | 6.11G/9.94G [00:18<00:14, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  62%|██████▏   | 6.16G/9.94G [00:19<00:12, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  62%|██████▏   | 6.20G/9.94G [00:19<00:12, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  63%|██████▎   | 6.23G/9.94G [00:19<00:12, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  63%|██████▎   | 6.27G/9.94G [00:19<00:12, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  63%|██████▎   | 6.31G/9.94G [00:19<00:11, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  64%|██████▍   | 6.35G/9.94G [00:19<00:11, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  64%|██████▍   | 6.40G/9.94G [00:19<00:11, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  65%|██████▍   | 6.44G/9.94G [00:19<00:11, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  65%|██████▌   | 6.47G/9.94G [00:20<00:11, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  65%|██████▌   | 6.50G/9.94G [00:20<00:12, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  66%|██████▌   | 6.54G/9.94G [00:20<00:10, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  66%|██████▌   | 6.59G/9.94G [00:20<00:10, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  67%|██████▋   | 6.63G/9.94G [00:20<00:10, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  67%|██████▋   | 6.67G/9.94G [00:20<00:09, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  67%|██████▋   | 6.71G/9.94G [00:20<00:09, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  68%|██████▊   | 6.75G/9.94G [00:20<00:10, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  68%|██████▊   | 6.79G/9.94G [00:21<00:10, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  69%|██████▉   | 6.84G/9.94G [00:21<00:10, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  69%|██████▉   | 6.87G/9.94G [00:21<00:10, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  69%|██████▉   | 6.91G/9.94G [00:21<00:09, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  70%|██████▉   | 6.95G/9.94G [00:21<00:09, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  70%|███████   | 6.98G/9.94G [00:21<00:09, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  71%|███████   | 7.03G/9.94G [00:21<00:09, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  71%|███████   | 7.07G/9.94G [00:21<00:09, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  71%|███████▏  | 7.10G/9.94G [00:22<00:09, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  72%|███████▏  | 7.14G/9.94G [00:22<00:08, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  72%|███████▏  | 7.18G/9.94G [00:22<00:08, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  73%|███████▎  | 7.22G/9.94G [00:22<00:08, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  73%|███████▎  | 7.27G/9.94G [00:22<00:11, 240MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  73%|███████▎  | 7.30G/9.94G [00:22<00:10, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  74%|███████▎  | 7.33G/9.94G [00:22<00:10, 252MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  74%|███████▍  | 7.37G/9.94G [00:23<00:09, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  75%|███████▍  | 7.41G/9.94G [00:23<00:08, 296MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  75%|███████▍  | 7.46G/9.94G [00:23<00:08, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  75%|███████▌  | 7.50G/9.94G [00:23<00:07, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  76%|███████▌  | 7.54G/9.94G [00:23<00:08, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  76%|███████▌  | 7.58G/9.94G [00:23<00:07, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  77%|███████▋  | 7.62G/9.94G [00:23<00:07, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  77%|███████▋  | 7.67G/9.94G [00:23<00:06, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  78%|███████▊  | 7.71G/9.94G [00:24<00:06, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  78%|███████▊  | 7.75G/9.94G [00:24<00:06, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  78%|███████▊  | 7.79G/9.94G [00:24<00:06, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  79%|███████▉  | 7.83G/9.94G [00:24<00:06, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  79%|███████▉  | 7.87G/9.94G [00:24<00:06, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  80%|███████▉  | 7.92G/9.94G [00:24<00:06, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  80%|████████  | 7.96G/9.94G [00:24<00:06, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  80%|████████  | 8.00G/9.94G [00:24<00:06, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  81%|████████  | 8.04G/9.94G [00:25<00:05, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  81%|████████▏ | 8.08G/9.94G [00:25<00:05, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  82%|████████▏ | 8.13G/9.94G [00:25<00:05, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  82%|████████▏ | 8.17G/9.94G [00:25<00:05, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  83%|████████▎ | 8.21G/9.94G [00:25<00:05, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  83%|████████▎ | 8.25G/9.94G [00:25<00:05, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  83%|████████▎ | 8.29G/9.94G [00:25<00:05, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  84%|████████▍ | 8.34G/9.94G [00:26<00:04, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  84%|████████▍ | 8.38G/9.94G [00:26<00:04, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  85%|████████▍ | 8.42G/9.94G [00:26<00:04, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  85%|████████▌ | 8.46G/9.94G [00:26<00:04, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  86%|████████▌ | 8.50G/9.94G [00:26<00:04, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  86%|████████▌ | 8.55G/9.94G [00:26<00:04, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  86%|████████▋ | 8.60G/9.94G [00:26<00:03, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  87%|████████▋ | 8.64G/9.94G [00:26<00:03, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  87%|████████▋ | 8.69G/9.94G [00:27<00:03, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  88%|████████▊ | 8.73G/9.94G [00:27<00:03, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  88%|████████▊ | 8.78G/9.94G [00:27<00:03, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  89%|████████▊ | 8.82G/9.94G [00:27<00:03, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  89%|████████▉ | 8.86G/9.94G [00:27<00:03, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  90%|████████▉ | 8.90G/9.94G [00:27<00:02, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  90%|████████▉ | 8.94G/9.94G [00:27<00:02, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  90%|█████████ | 8.99G/9.94G [00:27<00:02, 351MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  91%|█████████ | 9.03G/9.94G [00:28<00:02, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  91%|█████████ | 9.07G/9.94G [00:28<00:02, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  92%|█████████▏| 9.11G/9.94G [00:28<00:02, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  92%|█████████▏| 9.15G/9.94G [00:28<00:02, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  92%|█████████▏| 9.20G/9.94G [00:28<00:02, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  93%|█████████▎| 9.24G/9.94G [00:28<00:02, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  93%|█████████▎| 9.28G/9.94G [00:28<00:02, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  94%|█████████▍| 9.32G/9.94G [00:28<00:01, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  94%|█████████▍| 9.36G/9.94G [00:29<00:01, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  95%|█████████▍| 9.41G/9.94G [00:29<00:01, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  95%|█████████▌| 9.45G/9.94G [00:29<00:01, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  95%|█████████▌| 9.49G/9.94G [00:29<00:01, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  96%|█████████▌| 9.53G/9.94G [00:29<00:01, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  96%|█████████▋| 9.57G/9.94G [00:29<00:01, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  97%|█████████▋| 9.62G/9.94G [00:29<00:01, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  97%|█████████▋| 9.66G/9.94G [00:29<00:00, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  98%|█████████▊| 9.70G/9.94G [00:30<00:00, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  98%|█████████▊| 9.74G/9.94G [00:30<00:00, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  98%|█████████▊| 9.78G/9.94G [00:30<00:00, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  99%|█████████▉| 9.83G/9.94G [00:30<00:00, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors:  99%|█████████▉| 9.88G/9.94G [00:30<00:00, 362MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00001-of-00002.safetensors: 100%|█████████▉| 9.92G/9.94G [00:30<00:00, 336MB/s]#033[A#015model-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:30<00:00, 323MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading shards:  50%|█████     | 1/2 [00:30<00:30, 30.95s/it]\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   1%|          | 31.5M/4.54G [00:00<00:15, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   1%|▏         | 62.9M/4.54G [00:00<00:15, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   2%|▏         | 105M/4.54G [00:00<00:13, 318MB/s] #033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   3%|▎         | 157M/4.54G [00:00<00:12, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   4%|▍         | 199M/4.54G [00:00<00:13, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   5%|▌         | 241M/4.54G [00:00<00:13, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   6%|▌         | 283M/4.54G [00:00<00:13, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   7%|▋         | 325M/4.54G [00:00<00:12, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   8%|▊         | 367M/4.54G [00:01<00:13, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:   9%|▉         | 409M/4.54G [00:01<00:12, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  10%|▉         | 451M/4.54G [00:01<00:12, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  11%|█         | 493M/4.54G [00:01<00:12, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  12%|█▏        | 535M/4.54G [00:01<00:12, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  13%|█▎        | 577M/4.54G [00:01<00:17, 233MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  14%|█▍        | 629M/4.54G [00:02<00:13, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  15%|█▍        | 671M/4.54G [00:02<00:12, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  16%|█▌        | 713M/4.54G [00:02<00:12, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  17%|█▋        | 755M/4.54G [00:02<00:11, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  18%|█▊        | 797M/4.54G [00:02<00:11, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  18%|█▊        | 839M/4.54G [00:02<00:11, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  19%|█▉        | 881M/4.54G [00:02<00:11, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  20%|██        | 923M/4.54G [00:02<00:11, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  21%|██        | 965M/4.54G [00:03<00:10, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  22%|██▏       | 1.01G/4.54G [00:03<00:10, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  23%|██▎       | 1.06G/4.54G [00:03<00:09, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  24%|██▍       | 1.10G/4.54G [00:03<00:09, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  25%|██▌       | 1.14G/4.54G [00:03<00:09, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  26%|██▋       | 1.20G/4.54G [00:03<00:08, 374MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  27%|██▋       | 1.25G/4.54G [00:03<00:08, 386MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  29%|██▊       | 1.30G/4.54G [00:03<00:08, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  30%|██▉       | 1.34G/4.54G [00:04<00:08, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  30%|███       | 1.38G/4.54G [00:04<00:08, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  31%|███▏      | 1.43G/4.54G [00:04<00:09, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  32%|███▏      | 1.47G/4.54G [00:04<00:09, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  33%|███▎      | 1.51G/4.54G [00:04<00:08, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  34%|███▍      | 1.55G/4.54G [00:04<00:08, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  35%|███▌      | 1.59G/4.54G [00:04<00:08, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  36%|███▌      | 1.64G/4.54G [00:04<00:08, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  37%|███▋      | 1.68G/4.54G [00:05<00:07, 369MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  38%|███▊      | 1.72G/4.54G [00:05<00:07, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  39%|███▉      | 1.76G/4.54G [00:05<00:07, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  40%|███▉      | 1.80G/4.54G [00:05<00:07, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  41%|████      | 1.85G/4.54G [00:05<00:07, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  42%|████▏     | 1.89G/4.54G [00:05<00:07, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  42%|████▏     | 1.93G/4.54G [00:05<00:07, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  43%|████▎     | 1.97G/4.54G [00:05<00:07, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  45%|████▍     | 2.02G/4.54G [00:05<00:06, 379MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  45%|████▌     | 2.07G/4.54G [00:06<00:06, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  46%|████▋     | 2.11G/4.54G [00:06<00:06, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  47%|████▋     | 2.15G/4.54G [00:06<00:07, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  48%|████▊     | 2.19G/4.54G [00:06<00:07, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  49%|████▉     | 2.23G/4.54G [00:06<00:06, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  50%|█████     | 2.28G/4.54G [00:06<00:06, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  51%|█████     | 2.32G/4.54G [00:06<00:06, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  52%|█████▏    | 2.36G/4.54G [00:06<00:06, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  53%|█████▎    | 2.40G/4.54G [00:07<00:06, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  54%|█████▍    | 2.44G/4.54G [00:07<00:06, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  55%|█████▍    | 2.50G/4.54G [00:07<00:05, 360MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  56%|█████▌    | 2.54G/4.54G [00:07<00:05, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  57%|█████▋    | 2.58G/4.54G [00:07<00:05, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  58%|█████▊    | 2.62G/4.54G [00:07<00:05, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  59%|█████▊    | 2.66G/4.54G [00:07<00:05, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  60%|█████▉    | 2.71G/4.54G [00:07<00:05, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  61%|██████    | 2.75G/4.54G [00:08<00:04, 363MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  61%|██████▏   | 2.79G/4.54G [00:08<00:04, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  62%|██████▏   | 2.83G/4.54G [00:08<00:05, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  63%|██████▎   | 2.87G/4.54G [00:08<00:04, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  64%|██████▍   | 2.92G/4.54G [00:08<00:04, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  65%|██████▌   | 2.96G/4.54G [00:08<00:04, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  66%|██████▌   | 3.00G/4.54G [00:08<00:04, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  67%|██████▋   | 3.04G/4.54G [00:08<00:04, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  68%|██████▊   | 3.08G/4.54G [00:09<00:04, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  69%|██████▉   | 3.12G/4.54G [00:09<00:04, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  70%|██████▉   | 3.17G/4.54G [00:09<00:04, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  71%|███████   | 3.21G/4.54G [00:09<00:04, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  72%|███████▏  | 3.25G/4.54G [00:09<00:03, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  73%|███████▎  | 3.29G/4.54G [00:09<00:03, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  73%|███████▎  | 3.33G/4.54G [00:09<00:03, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  74%|███████▍  | 3.38G/4.54G [00:09<00:03, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  76%|███████▌  | 3.43G/4.54G [00:10<00:03, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  76%|███████▋  | 3.47G/4.54G [00:10<00:03, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  77%|███████▋  | 3.50G/4.54G [00:10<00:04, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  78%|███████▊  | 3.53G/4.54G [00:10<00:04, 249MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  79%|███████▊  | 3.57G/4.54G [00:10<00:03, 247MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  79%|███████▉  | 3.60G/4.54G [00:10<00:03, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  80%|████████  | 3.64G/4.54G [00:10<00:03, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  81%|████████  | 3.68G/4.54G [00:11<00:02, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  82%|████████▏ | 3.72G/4.54G [00:11<00:02, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  83%|████████▎ | 3.76G/4.54G [00:11<00:02, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  84%|████████▎ | 3.80G/4.54G [00:11<00:02, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  84%|████████▍ | 3.83G/4.54G [00:11<00:02, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  85%|████████▌ | 3.87G/4.54G [00:11<00:02, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  86%|████████▌ | 3.91G/4.54G [00:11<00:02, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  87%|████████▋ | 3.94G/4.54G [00:12<00:02, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  88%|████████▊ | 3.98G/4.54G [00:12<00:01, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  89%|████████▊ | 4.03G/4.54G [00:12<00:01, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  90%|████████▉ | 4.07G/4.54G [00:12<00:01, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  91%|█████████ | 4.11G/4.54G [00:12<00:01, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  91%|█████████▏| 4.15G/4.54G [00:12<00:01, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  92%|█████████▏| 4.19G/4.54G [00:12<00:01, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  94%|█████████▎| 4.25G/4.54G [00:12<00:00, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  94%|█████████▍| 4.29G/4.54G [00:13<00:00, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  95%|█████████▌| 4.33G/4.54G [00:13<00:00, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  96%|█████████▋| 4.37G/4.54G [00:13<00:00, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  97%|█████████▋| 4.41G/4.54G [00:13<00:00, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  98%|█████████▊| 4.46G/4.54G [00:13<00:00, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34m#015model-00002-of-00002.safetensors:  99%|█████████▉| 4.51G/4.54G [00:13<00:00, 373MB/s]#033[A#015model-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:13<00:00, 332MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading shards: 100%|██████████| 2/2 [00:44<00:00, 20.85s/it]#015Downloading shards: 100%|██████████| 2/2 [00:44<00:00, 22.36s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]\u001b[0m\n",
      "\u001b[34m#015generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]#015generation_config.json: 100%|██████████| 116/116 [00:00<00:00, 1.38MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['gate_proj', 'q_proj', 'up_proj', 'down_proj', 'v_proj', 'o_proj', 'k_proj']\u001b[0m\n",
      "\u001b[34mtrainable params: 167772160 || all params: 3919843328 || trainable%: 4.280073103982997\u001b[0m\n",
      "\u001b[34m{'loss': 1.7268, 'learning_rate': 0.00018, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'loss': 1.4935, 'learning_rate': 0.00016, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m{'loss': 1.3067, 'learning_rate': 0.00014, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m{'loss': 1.1297, 'learning_rate': 0.00012, 'epoch': 4.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.9664, 'learning_rate': 0.0001, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8133, 'learning_rate': 8e-05, 'epoch': 6.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6784, 'learning_rate': 6e-05, 'epoch': 7.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5658, 'learning_rate': 4e-05, 'epoch': 8.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4801, 'learning_rate': 2e-05, 'epoch': 9.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4266, 'learning_rate': 0.0, 'epoch': 10.0}\u001b[0m\n",
      "\u001b[34m{'train_runtime': 171.8485, 'train_samples_per_second': 0.233, 'train_steps_per_second': 0.116, 'train_loss': 0.9587349057197571, 'epoch': 10.0}\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/20 [00:00<?, ?it/s]#015  5%|▌         | 1/20 [00:08<02:49,  8.94s/it]#015 10%|█         | 2/20 [00:17<02:36,  8.72s/it]#015                                              #015#015 10%|█         | 2/20 [00:17<02:36,  8.72s/it]#015 15%|█▌        | 3/20 [00:26<02:27,  8.66s/it]#015 20%|██        | 4/20 [00:34<02:17,  8.62s/it]#015                                              #015#015 20%|██        | 4/20 [00:34<02:17,  8.62s/it]#015 25%|██▌       | 5/20 [00:43<02:09,  8.61s/it]#015 30%|███       | 6/20 [00:51<02:00,  8.59s/it]#015                                              #015#015 30%|███       | 6/20 [00:51<02:00,  8.59s/it]#015 35%|███▌      | 7/20 [01:00<01:51,  8.59s/it]#015 40%|████      | 8/20 [01:08<01:42,  8.58s/it]#015                                              #015#015 40%|████      | 8/20 [01:08<01:42,  8.58s/it]#015 45%|████▌     | 9/20 [01:17<01:34,  8.58s/it]#015 50%|█████     | 10/20 [01:26<01:25,  8.58s/it]#015                                               #015#015 50%|█████     | 10/20 [01:26<01:25,  8.58s/it]#015 55%|█████▌    | 11/20 [01:34<01:17,  8.58s/it]#015 60%|██████    | 12/20 [01:43<01:08,  8.58s/it]#015                                               #015#015 60%|██████    | 12/20 [01:43<01:08,  8.58s/it]#015 65%|██████▌   | 13/20 [01:51<01:00,  8.58s/it]#015 70%|███████   | 14/20 [02:00<00:51,  8.57s/it]#015                                               #015#015 70%|███████   | 14/20 [02:00<00:51,  8.57s/it]#015 75%|███████▌  | 15/20 [02:08<00:42,  8.58s/it]#015 80%|████████  | 16/20 [02:17<00:34,  8.57s/it]#015                                               #015#015 80%|████████  | 16/20 [02:17<00:34,  8.57s/it]#015 85%|████████▌ | 17/20 [02:26<00:25,  8.58s/it]#015 90%|█████████ | 18/20 [02:34<00:17,  8.57s/it]#015                                               #015#015 90%|█████████ | 18/20 [02:34<00:17,  8.57s/it]#015 95%|█████████▌| 19/20 [02:43<00:08,  8.58s/it]#015100%|██████████| 20/20 [02:51<00:00,  8.57s/it]#015                                               #015#015100%|██████████| 20/20 [02:51<00:00,  8.57s/it]#015                                               #015#015100%|██████████| 20/20 [02:51<00:00,  8.57s/it]#015100%|██████████| 20/20 [02:51<00:00,  8.59s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.08s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.11it/s]\u001b[0m\n",
      "\u001b[34m#015tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]#015tokenizer_config.json: 100%|██████████| 1.47k/1.47k [00:00<00:00, 16.6MB/s]\u001b[0m\n",
      "\u001b[34m#015tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]#015tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 94.5MB/s]\u001b[0m\n",
      "\u001b[34m#015tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]#015tokenizer.json: 100%|██████████| 1.80M/1.80M [00:00<00:00, 12.4MB/s]#015tokenizer.json: 100%|██████████| 1.80M/1.80M [00:00<00:00, 12.3MB/s]\u001b[0m\n",
      "\u001b[34m#015special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]#015special_tokens_map.json: 100%|██████████| 72.0/72.0 [00:00<00:00, 968kB/s]\u001b[0m\n",
      "\u001b[34m2024-02-05 01:06:16,016 sagemaker.remote_function INFO     Serializing the function return and uploading to s3://sagemaker-eu-west-1-691148928602/train-Mistral-7B-Instruct-v0-1-merge-2024-02-05-00-55-41-107/results\u001b[0m\n",
      "\n",
      "2024-02-05 01:06:39 Uploading - Uploading generated training model\n",
      "2024-02-05 01:07:25 Completed - Training job completed\n",
      "Training seconds: 603\n",
      "Billable seconds: 603\n"
     ]
    }
   ],
   "source": [
    "train_fn(\n",
    "    model_id,\n",
    "    train_dataset,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    chunk_size=2048,\n",
    "    merge_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Fine-Tuned model\n",
    "\n",
    "Note: Run `train_fn` with `merge_weights=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:08.515277Z",
     "start_time": "2023-11-20T18:41:08.503555Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:09.025472Z",
     "start_time": "2023-11-20T18:41:09.021475Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "bucket_name = \"<S3_BUCKET>\"\n",
    "job_prefix = f\"train-{model_id.split('/')[-1].replace('.', '-')}-merge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_job_name(job_name_prefix):\n",
    "    import boto3\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    \n",
    "    search_response = sagemaker_client.search(\n",
    "        Resource='TrainingJob',\n",
    "        SearchExpression={\n",
    "            'Filters': [\n",
    "                {\n",
    "                    'Name': 'TrainingJobName',\n",
    "                    'Operator': 'Contains',\n",
    "                    'Value': job_name_prefix\n",
    "                },\n",
    "                {\n",
    "                    'Name': 'TrainingJobStatus',\n",
    "                    'Operator': 'Equals',\n",
    "                    'Value': \"Completed\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "        MaxResults=1)\n",
    "    \n",
    "    return search_response['Results'][0]['TrainingJob']['TrainingJobName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = get_last_job_name(job_prefix)\n",
    "\n",
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Inference configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:10.492877Z",
     "start_time": "2023-11-20T18:41:10.488495Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "number_of_gpu = 4\n",
    "health_check_timeout = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:11.162811Z",
     "start_time": "2023-11-20T18:41:10.787936Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = get_huggingface_llm_image_uri(\n",
    "    \"huggingface\",\n",
    "    version=\"1.1.0\"\n",
    ")\n",
    "\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:41:12.433399Z",
     "start_time": "2023-11-20T18:41:11.963091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = HuggingFaceModel(\n",
    "    image_uri=image_uri,\n",
    "    model_data=f\"s3://{bucket_name}/{job_name}/{job_name}/output/model.tar.gz\",\n",
    "    env={\n",
    "        'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "        'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:45:49.265298Z",
     "start_time": "2023-11-20T18:41:14.621743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:48:12.482198Z",
     "start_time": "2023-11-20T18:48:12.471432Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "base_prompt = f\"\"\"\n",
    "<s>[INST]\n",
    "{{question}} \n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:48:49.471611Z",
     "start_time": "2023-11-20T18:48:44.127852Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = base_prompt.format(question=\"Which are the Foundation Models available in Amazon Bedrock?\")\n",
    "\n",
    "predictor.predict({\n",
    "\t\"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 2048 - len(prompt),\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T18:48:55.153276Z",
     "start_time": "2023-11-20T18:48:54.165351Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
